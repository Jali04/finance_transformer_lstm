{
    "cells": [
        {
            "cell_type": "code",
            "execution_count": 1,
            "id": "0815ad64-f59a-4d0c-931c-066a8ffbbf67",
            "metadata": {},
            "outputs": [],
            "source": [
                "# === REPORT GENERATOR ===\n",
                "# 07_report.ipynb\n",
                "# Dieser Block sammelt alle Ergebnisse (Metriken, Plots, Backtests) ein und erstellt\n",
                "# einen übersichtlichen Abschlussbericht (Markdown).\n",
                "# Er sucht automatisch nach dem neuesten Run-Verzeichnis."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 2,
            "id": "db17a3bd-70e4-4b31-967b-b18ec77373a0",
            "metadata": {},
            "outputs": [],
            "source": [
                "import os, json, yaml, re\n",
                "from pathlib import Path\n",
                "from datetime import datetime\n",
                "import numpy as np\n",
                "import pandas as pd"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 3,
            "id": "aabe6ed9-b8f0-4843-9051-3352546c50c2",
            "metadata": {},
            "outputs": [],
            "source": [
                "# === HELFER: RUN FINDEN ===\n",
                "# Funktionalität, um den richtigen Ordner basierend auf Config-Parametern zu finden.\n",
                "def jread(p: Path):\n",
                "    with open(p, \"r\", encoding=\"utf-8\") as f:\n",
                "        return json.load(f)\n",
                "\n",
                "def latest_lstm_run(results_dir: Path,\n",
                "                    lookback: int = None,\n",
                "                    horizon: int = None,\n",
                "                    eps_mode: str = None,\n",
                "                    epsilon: float = None,\n",
                "                    strict: bool = False) -> Path | None:\n",
                "    # Sortiert nach Datum (neuestes zuerst)\n",
                "    runs = sorted(results_dir.glob(\"*_lstm\"), key=lambda p: p.stat().st_mtime, reverse=True)\n",
                "    if not runs:\n",
                "        return None\n",
                "\n",
                "    # Filter-Logik\n",
                "    def matches(run: Path) -> bool:\n",
                "        try:\n",
                "            cfg = jread(run / \"config.json\")\n",
                "        except Exception:\n",
                "            return False\n",
                "        ok_lb = (lookback is None) or (int(cfg.get(\"lookback\", -1)) == lookback)\n",
                "        tc = str(cfg.get(\"train_csv\", \"\"))\n",
                "        mH = re.search(r\"_cls_h(\\d+)_\", tc)\n",
                "        mE = re.search(r\"_(abs|rel)([\\dp]+)\\.csv$\", tc)\n",
                "        ok_h = True if horizon is None else (int(cfg.get(\"horizon\", -1)) == horizon or (mH and int(mH.group(1)) == horizon))\n",
                "        ok_m = True if eps_mode is None else ((mE and mE.group(1) == eps_mode))\n",
                "        ok_e = True\n",
                "        if epsilon is not None:\n",
                "            if mE:\n",
                "                ok_e = float(mE.group(2).replace(\"p\",\".\")) == float(epsilon)\n",
                "            else:\n",
                "                ok_e = float(cfg.get(\"epsilon\", 1e9)) == float(epsilon)\n",
                "        return ok_lb and ok_h and ok_m and ok_e\n",
                "\n",
                "    matches_list = [r for r in runs if matches(r)]\n",
                "    if matches_list:\n",
                "        return matches_list[0]\n",
                "    return None if strict else runs[0]"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 4,
            "id": "2829a180-c092-4e26-9e97-b2be4b71c411",
            "metadata": {},
            "outputs": [],
            "source": [
                "# === CONFIG LADEN ===\n",
                "ROOT = Path(\"..\").resolve()\n",
                "with open(ROOT / \"config.json\", \"r\") as f:\n",
                "    C = json.load(f)\n",
                "\n",
                "RESULTS_DIR = Path(C.get(\"results_dir\", \"../results\")).resolve()\n",
                "LOOKBACK    = int(C[\"lookback\"])\n",
                "FEATURESET  = C.get(\"featureset\", \"v2\")\n",
                "\n",
                "# Versuchen, Label-Definition aus YAML zu holen\n",
                "HORIZON = MODE = EPS = None\n",
                "yml = ROOT / f\"data/features_{FEATURESET}.yml\"\n",
                "if yml.exists():\n",
                "    meta = yaml.safe_load(open(yml, \"r\")) or {}\n",
                "    lab = meta.get(\"label\", {})\n",
                "    HORIZON = int(lab.get(\"horizon\", 0)) or None\n",
                "    MODE    = str(lab.get(\"mode\", \"\")) or None\n",
                "    EPS     = float(lab.get(\"epsilon\", 0.0)) or None"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 5,
            "id": "b898427f-16bc-44dd-ba5e-5f2abd283aea",
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "RUN_DIR -> C:\\Users\\jacin\\DL_PROJECT\\finance_transformer_lstm\\LSTM\\results\\2026-01-01_18-20-06_lstm\n"
                    ]
                }
            ],
            "source": [
                "# === RUN-VERZEICHNIS BESTIMMEN ===\n",
                "run_override = os.getenv(\"RUN_DIR\", \"\").strip() or None\n",
                "if run_override:\n",
                "    RUN_DIR = Path(run_override).resolve()\n",
                "else:\n",
                "    RUN_DIR = latest_lstm_run(RESULTS_DIR, lookback=LOOKBACK, horizon=HORIZON, eps_mode=MODE, epsilon=EPS, strict=False)\n",
                "\n",
                "if RUN_DIR is None or not RUN_DIR.exists():\n",
                "    raise SystemExit(\"Kein *_lstm Run gefunden. Bitte Block 3/4/6 vorher einmal ausführen.\")\n",
                "\n",
                "print(\"RUN_DIR ->\", RUN_DIR)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 6,
            "id": "23f9e4fd-dafa-468d-8049-f2437e2e2cb7",
            "metadata": {},
            "outputs": [],
            "source": [
                "# === ARTEFAKTE EINLESEN ===\n",
                "# Wir holen uns alles, was die vorherigen Notebooks (4 & 6) produziert haben.\n",
                "ev_path = RUN_DIR / \"evaluation.json\"\n",
                "if not ev_path.exists():\n",
                "    raise SystemExit(f\"evaluation.json fehlt in {RUN_DIR} (Block 4/6).\")\n",
                "\n",
                "ev    = jread(ev_path)\n",
                "cfg   = ev.get(\"config\", {})\n",
                "metrics = (ev.get(\"metrics\", {}) or {}).get(\"test\", {})\n",
                "thr_sel = ev.get(\"threshold_selection\", {})\n",
                "calib   = ev.get(\"calibration\", {})\n",
                "backtest_gross = ev.get(\"backtest\", {})\n",
                "\n",
                "# Fallback: Wenn wir oben keine Label-Info gefunden haben, nehmen wir sie aus den Logs\n",
                "if HORIZON is None:\n",
                "    HORIZON = int(((ev.get(\"label_resolved_from\") or {}).get(\"horizon\")) or cfg.get(\"horizon\"))\n",
                "if MODE is None:\n",
                "    MODE = (ev.get(\"label_resolved_from\") or {}).get(\"mode\") or cfg.get(\"epsilon_mode\")\n",
                "if EPS is None:\n",
                "    EPS = float((ev.get(\"label_resolved_from\") or {}).get(\"epsilon\") or cfg.get(\"epsilon\"))"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 7,
            "id": "0407107f-a03e-4891-856e-c16726338a5a",
            "metadata": {},
            "outputs": [],
            "source": [
                "# === KOSTEN-DATEN LADEN ===\n",
                "# Wir suchen die Zeile aus der Sensitivitätsanalyse, die unseren Hauptannahmen entspricht.\n",
                "sens_path = RUN_DIR / \"cost_sensitivity.csv\"\n",
                "sens_df = pd.read_csv(sens_path) if sens_path.exists() else None\n",
                "\n",
                "MAIN_RT = 15.0  # Annahme: 15 bps Roundtrip\n",
                "MAIN_SLIP_PER_LEG = 2.0\n",
                "\n",
                "cost_pick = {}\n",
                "if sens_df is not None and len(sens_df):\n",
                "    # Wir wollen nur \"Entry@t+1\" Ergebnisse, da dies unser realistisches Modell ist\n",
                "    df_t1_exact = sens_df[sens_df[\"model\"] == \"Entry@t+1\"]\n",
                "    df_t1_prefix = sens_df[sens_df[\"model\"].astype(str).str.startswith(\"Entry@t+1\")]\n",
                "    df_t1 = df_t1_exact if len(df_t1_exact) else df_t1_prefix\n",
                "\n",
                "    if not len(df_t1):\n",
                "        df_t1 = sens_df.copy() # Fallback\n",
                "\n",
                "    # Finde den Eintrag, der am nächsten an unseren 15bps liegt\n",
                "    df_t1[\"rt_diff\"] = (df_t1[\"roundtrip_bps\"] - MAIN_RT).abs()\n",
                "    row = df_t1.sort_values([\"rt_diff\", \"roundtrip_bps\"]).iloc[0].to_dict()\n",
                "    cost_pick = dict(\n",
                "        model=row[\"model\"], roundtrip_bps=float(row[\"roundtrip_bps\"]),\n",
                "        trades=int(row.get(\"trades\", 0)), exposure=float(row.get(\"exposure\", np.nan)),\n",
                "        turnover=float(row.get(\"turnover\", np.nan)),\n",
                "        CAGR=float(row[\"CAGR\"]), Sharpe=float(row[\"Sharpe\"]), MaxDD=float(row[\"MaxDD\"]),\n",
                "        final_equity=float(row[\"final_equity\"]),\n",
                "    )"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 8,
            "id": "69024c17-9f6c-4017-97de-5b7c461aff18",
            "metadata": {},
            "outputs": [],
            "source": [
                "# === BASELINES BERECHNEN ===\n",
                "# Um zu wissen, ob unser Modell \"gut\" ist, vergleichen wir es mit simplen Strategien.\n",
                "# Hier berechnen wir LogReg und MACD neu auf EXAKT den gleichen Daten.\n",
                "TRAIN_CSV = Path(cfg.get(\"train_csv\", \"\"))\n",
                "features_list = cfg.get(\"features\", None)\n",
                "if not features_list:\n",
                "    # Fallback YAML\n",
                "    yml = ROOT / f\"data/features_{FEATURESET}.yml\"\n",
                "    if yml.exists():\n",
                "        meta = yaml.safe_load(open(yml, \"r\")) or {}\n",
                "        features_list = meta.get(\"features\", [])\n",
                "\n",
                "# Daten laden & Splitten\n",
                "df_all = pd.read_csv(TRAIN_CSV, index_col=0, parse_dates=True).sort_index()\n",
                "X_all = df_all[features_list].copy()\n",
                "y_all = df_all[\"target\"].astype(int).copy()\n",
                "\n",
                "n = len(df_all)\n",
                "n_train = int(n * 0.70)\n",
                "n_val   = int(n * 0.15)\n",
                "n_test  = n - n_train - n_val\n",
                "\n",
                "X_train, y_train = X_all.iloc[:n_train],              y_all.iloc[:n_train]\n",
                "X_val,   y_val   = X_all.iloc[n_train:n_train+n_val], y_all.iloc[n_train:n_train+n_val]\n",
                "X_test,  y_test  = X_all.iloc[n_train+n_val:],        y_all.iloc[n_train+n_val:]\n",
                "\n",
                "# Scaling (Fit auf Train, Transform auf alle)\n",
                "LB = int(cfg.get(\"lookback\", LOOKBACK))\n",
                "from sklearn.preprocessing import StandardScaler\n",
                "from sklearn.linear_model import LogisticRegression\n",
                "from sklearn.metrics import average_precision_score\n",
                "\n",
                "scaler = StandardScaler().fit(X_train)\n",
                "Xtr_s = pd.DataFrame(scaler.transform(X_train), index=X_train.index, columns=X_train.columns)\n",
                "Xva_s = pd.DataFrame(scaler.transform(X_val),   index=X_val.index,   columns=X_val.columns)\n",
                "Xte_s = pd.DataFrame(scaler.transform(X_test),  index=X_test.index,  columns=X_test.columns)\n",
                "\n",
                "tail = slice(LB-1, None)\n",
                "ytr_tail, yva_tail, yte_tail = y_train.iloc[tail], y_val.iloc[tail], y_test.iloc[tail]\n",
                "Xtr_tail, Xva_tail, Xte_tail = Xtr_s.iloc[tail],   Xva_s.iloc[tail],   Xte_s.iloc[tail]\n",
                "\n",
                "# 1. Baseline: Always-Up (Immer Long sein)\n",
                "pos_rate_test = float(yte_tail.mean())\n",
                "auprc_always_up = pos_rate_test\n",
                "\n",
                "# 2. Baseline: Logistische Regression (Lineares Modell)\n",
                "logit = LogisticRegression(max_iter=200)\n",
                "logit.fit(Xtr_tail, ytr_tail)\n",
                "proba_lr = logit.predict_proba(Xte_tail)[:,1]\n",
                "auprc_lr = float(average_precision_score(yte_tail, proba_lr))\n",
                "\n",
                "# 3. Baseline: Simpler MACD Indikator\n",
                "macd_diff = df_all.loc[Xte_tail.index, \"macd_diff\"].astype(float)\n",
                "if macd_diff.isna().any(): macd_diff = macd_diff.fillna(0.0)\n",
                "auprc_macd = float(average_precision_score(yte_tail, macd_diff.values))\n",
                "\n",
                "baselines_tbl = pd.DataFrame([\n",
                "    {\"baseline\": \"Always-Up\", \"auprc\": auprc_always_up, \"pos_rate\": pos_rate_test,\n",
                "     \"auprc_over_posrate\": (auprc_always_up / max(pos_rate_test, 1e-12))},\n",
                "    {\"baseline\": \"Logistic Regression\", \"auprc\": auprc_lr, \"pos_rate\": pos_rate_test,\n",
                "     \"auprc_over_posrate\": (auprc_lr / max(pos_rate_test, 1e-12))},\n",
                "    {\"baseline\": \"Simple MACD (macd_diff score)\", \"auprc\": auprc_macd, \"pos_rate\": pos_rate_test,\n",
                "     \"auprc_over_posrate\": (auprc_macd / max(pos_rate_test, 1e-12))}\n",
                "])"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 9,
            "id": "57a3d6ad-a1c5-4a7e-83d1-bf5de33dc062",
            "metadata": {},
            "outputs": [],
            "source": [
                "# === DATEN ZUSAMMENFÜHREN ===\n",
                "# Riesiges Dictionary für den Report\n",
                "kpis = {\n",
                "    \"run_dir\": str(RUN_DIR),\n",
                "    \"generated_utc\": datetime.utcnow().isoformat(timespec=\"seconds\") + \"Z\",\n",
                "    \"data\": {\n",
                "        \"ticker\": cfg.get(\"ticker\"),\n",
                "        \"interval\": cfg.get(\"interval\"),\n",
                "        \"period\": [cfg.get(\"start\"), cfg.get(\"end\")],\n",
                "        \"horizon\": cfg.get(\"horizon\"),\n",
                "        \"lookback\": cfg.get(\"lookback\"),\n",
                "        \"featureset\": cfg.get(\"featureset\"),\n",
                "        \"features_used\": ev.get(\"features_used\"),\n",
                "    },\n",
                "    \"label\": ev.get(\"label_resolved_from\"),\n",
                "    \"calibration\": {\n",
                "        \"chosen\": calib.get(\"chosen\"),\n",
                "        \"val_brier\": calib.get(\"val_brier\"),\n",
                "        \"test_brier\": calib.get(\"test_brier\"),\n",
                "        \"note\": \"Kalibrationsentscheidung ausschließlich auf Validation; Test nur zur Berichterstattung.\"\n",
                "    },\n",
                "    \"threshold\": {\n",
                "        \"strategy\": thr_sel.get(\"strategy\"),\n",
                "        \"threshold\": thr_sel.get(\"threshold\"),\n",
                "        \"val_mcc\": thr_sel.get(\"val_mcc\"),\n",
                "        \"test_pred_pos_rate\": thr_sel.get(\"test_pred_pos_rate\"),\n",
                "    },\n",
                "    \"classification_test\": {\n",
                "        \"roc_auc\": metrics.get(\"roc_auc\"),\n",
                "        \"auprc\": metrics.get(\"auprc\"),\n",
                "        \"brier\": metrics.get(\"brier\"),\n",
                "        \"balanced_accuracy\": metrics.get(\"balanced_accuracy\"),\n",
                "        \"mcc\": metrics.get(\"mcc\"),\n",
                "        \"confusion_matrix\": metrics.get(\"confusion_matrix\"),\n",
                "    },\n",
                "    \"backtest_gross\": backtest_gross,     # Backtest ohne Kosten\n",
                "    \"backtest_cost_pick\": cost_pick,      # Realistischer Backtest (netto)\n",
                "    \"baselines\": baselines_tbl.to_dict(orient=\"records\")\n",
                "}"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 10,
            "id": "40e11499-04f4-45e6-9659-437cd867ed45",
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "✓ REPORT geschrieben → C:\\Users\\jacin\\DL_PROJECT\\finance_transformer_lstm\\LSTM\\results\\2026-01-01_18-20-06_lstm\\REPORT_block7.md\n"
                    ]
                }
            ],
            "source": [
                "# === REPORT GENERIEREN (MARKDOWN) ===\n",
                "fig_dir = RUN_DIR / \"figures\"\n",
                "figs = {\n",
                "    \"roc\": fig_dir / \"roc_test.png\",\n",
                "    \"pr\":  fig_dir / \"pr_test.png\",\n",
                "    \"calib\": fig_dir / \"calibration_test.png\",\n",
                "    \"cm\":   fig_dir / \"cm_test.png\",\n",
                "    \"proba\": fig_dir / \"proba_hist_raw_vs_used.png\",\n",
                "    \"equity_gross\": fig_dir / \"equity_curves_t_vs_t1.png\",\n",
                "    \"equity_cost\":  fig_dir / \"equity_costed.png\",\n",
                "}\n",
                "\n",
                "def _rel(p: Path) -> str:\n",
                "    return str(p.relative_to(RUN_DIR)) if p.exists() else str(p)\n",
                "\n",
                "report_md = RUN_DIR / \"REPORT_block7.md\"\n",
                "lines = []\n",
                "lines.append(f\"# Block 7 – Abschluss-Report\\n\")\n",
                "lines.append(f\"- **Run-Ordner:** `{RUN_DIR.name}`\")\n",
                "lines.append(f\"- **Erstellt (UTC):** {kpis['generated_utc']}\")\n",
                "lines.append(f\"- **Ticker/Intervall:** {kpis['data']['ticker']} / {kpis['data']['interval']}\")\n",
                "lines.append(f\"- **Zeitraum:** {kpis['data']['period'][0]} → {kpis['data']['period'][1]}\")\n",
                "lines.append(f\"- **Horizon/Lookback:** H={kpis['data']['horizon']} / LB={kpis['data']['lookback']}\")\n",
                "lines.append(f\"- **Featureset:** {kpis['data']['featureset']} → {', '.join(kpis['data']['features_used'])}\\n\")\n",
                "\n",
                "lines.append(\"## Test-Metriken\")\n",
                "m = kpis[\"classification_test\"]\n",
                "lines.append(f\"- AUROC: **{m['roc_auc']:.3f}**, AUPRC: **{m['auprc']:.3f}** (Random={m['auprc']:.2f}? Check PosRate), Brier: **{m['brier']:.3f}**\")\n",
                "lines.append(f\"- Balanced Acc: **{m['balanced_accuracy']:.3f}**, MCC: **{m['mcc']:.3f}**\\n\")\n",
                "lines.append(f\"![ROC]({_rel(figs['roc'])})  \\n![PR]({_rel(figs['pr'])})\\n\")\n",
                "\n",
                "lines.append(\"## Backtests\")\n",
                "bg = kpis[\"backtest_gross\"]\n",
                "if bg:\n",
                "    t  = bg.get(\"strategy_t\", {})\n",
                "    t1 = bg.get(\"strategy_t1\", {})\n",
                "    lines.append(f\"- **Gross (ohne Kosten)**: Entry@t CAGR={t.get('CAGR'):.3f}, Entry@t+1 CAGR={t1.get('CAGR'):.3f}\")\n",
                "\n",
                "cp = kpis[\"backtest_cost_pick\"]\n",
                "lines.append(\"## Kosten-KPI (realistisch)\")\n",
                "if cp:\n",
                "    lines.append(f\"- **Netto (mit Kosten)**: {cp['model']} @ {cp['roundtrip_bps']} bps. CAGR={cp['CAGR']:.3f}, Equity={cp['final_equity']:.3f}\")\n",
                "    lines.append(f\"![Equity net]({_rel(figs['equity_cost'])})\\n\")\n",
                "\n",
                "lines.append(\"## Limitations\")\n",
                "lines.append(\"- **Labeling:** Sensitivität gegenüber Epsilon ist hoch.\")\n",
                "lines.append(\"- **Markt-Regime:** Modell wurde über lange Zeit trainiert, Regimewechsel nicht explizit modelliert.\")\n",
                "lines.append(\"- **Daten:** Nur Preis/Volumen, keine Fundamentaldaten oder Sentiment.\\n\")\n",
                "\n",
                "report_md.write_text(\"\\n\".join(lines), encoding=\"utf-8\")\n",
                "print(\"✓ REPORT geschrieben →\", report_md)\n",
                "\n",
                "(RUN_DIR / \"REPORT_block7_kpis.json\").write_text(json.dumps(kpis, indent=2), encoding=\"utf-8\")\n",
                "\n",
                "# CSV Dump\n",
                "try:\n",
                "    kpi_rows = {\n",
                "        \"roc_auc\": metrics.get(\"roc_auc\"), \"auprc\": metrics.get(\"auprc\"), \"mcc\": metrics.get(\"mcc\"),\n",
                "        \"cost_CAGR\": cp.get(\"CAGR\") if cp else None,\n",
                "        \"cost_Sharpe\": cp.get(\"Sharpe\") if cp else None,\n",
                "    }\n",
                "    pd.DataFrame([kpi_rows]).to_csv(RUN_DIR / \"kpis_block7.csv\", index=False)\n",
                "except Exception as e:\n",
                "    print(\"Fehler beim CSV schreiben:\", e)"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.10.11"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 5
}
