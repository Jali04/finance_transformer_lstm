{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0e136527-d2d1-4569-a339-1bcbe8077d38",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === SYSTEM & IMPORTS ===\n",
    "# Block 6: Der Realitäts-Check (Costed Backtest)\n",
    "#\n",
    "# Hintergrund: Viele Trading-Strategien sehen \"auf dem Papier\" (ohne Kosten) gut aus.\n",
    "# Sobald man Transaktionskosten (Gebühren + Slippage) abzieht, verschwinden die Gewinne oft.\n",
    "# Dieses Notebook simuliert den Handel unter realistischen Bedingungen.\n",
    "\n",
    "import os, json, math\n",
    "from pathlib import Path\n",
    "\n",
    "# Datenanalyse\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Visualisierung\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b37a3408-28d9-4a9c-a92d-33d6e322eae5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === KOSTEN-MODELLE DEFINIEREN ===\n",
    "# Wir rechnen in \"Basispunkten\" (bps). 1 bp = 0.01%.\n",
    "\n",
    "# 1. Roundtrip-Kosten: Gebühren für Kauf + Verkauf zusammen.\n",
    "# 15 bps = 0.15%. Das ist typisch für günstige Retail-Broker (Spread + Commission).\n",
    "ROUNDTRIP_BPS_DEFAULT = 15.0\n",
    "\n",
    "# 2. Slippage: Der Markt bewegt sich oft gegen uns, während wir kaufen.\n",
    "# \"2.0 bps per leg\" bedeutet, wir zahlen beim Einstieg 0.02% mehr und beim Ausstieg kriegen wir 0.02% weniger.\n",
    "# Das simuliert die Zeitverzögerung und Markttiefe.\n",
    "SLIPPAGE_BPS_PER_LEG = 2.0\n",
    "\n",
    "# Sensitivitäts-Analyse: Wir testen verschiedene Kosten-Szenarien, um zu sehen, wie robust die Strategie ist.\n",
    "# Von sehr günstig (5 bps) bis sehr teuer (100 bps).\n",
    "SENSI_BPS = [5.0, 10.0, 15.0, 25.0, 50.0, 100.0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e102defb-2866-4dbe-bebc-67624bd7cd58",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === ARTEFAKTE LADEN ===\n",
    "# Wir holen uns die Ergebnisse des letzten Runs.\n",
    "\n",
    "ROOT = Path(\"..\")\n",
    "# Config laden, um Pfade zu finden\n",
    "with open(ROOT/\"config.json\",\"r\") as f:\n",
    "    C = json.load(f)\n",
    "\n",
    "# Neuesten LSTM-Run suchen (im results Verzeichnis)\n",
    "RESULTS_DIR = Path(C.get(\"results_dir\",\"../results\"))\n",
    "runs = sorted(RESULTS_DIR.glob(\"*_lstm\"), key=lambda p: p.stat().st_mtime, reverse=True)\n",
    "assert runs, \"Kein *_lstm Run-Ordner gefunden. Bitte erst trainieren!\"\n",
    "RUN_DIR = runs[0] # Der aktuellste\n",
    "\n",
    "# Run-Config laden, um Parameter des Experiments zu kennen\n",
    "with open(RUN_DIR/\"config.json\",\"r\") as f:\n",
    "    RCFG = json.load(f)\n",
    "\n",
    "# Metadaten wiederherstellen\n",
    "TRAIN_CSV = Path(RCFG[\"train_csv\"])\n",
    "H = int(RCFG[\"horizon\"])    # Haltedauer in Tagen\n",
    "LOOKBACK = int(RCFG[\"lookback\"])\n",
    "\n",
    "# Vorhersagen (Test-Set) laden, die in Block 4 gespeichert wurden\n",
    "# Dies enthält die 'proba_used' (kalibrierte Wahrscheinlichkeiten)\n",
    "preds = pd.read_csv(RUN_DIR/\"preds_test.csv\", parse_dates=[\"timestamp\"]).set_index(\"timestamp\").sort_index()\n",
    "\n",
    "# Original-Marktdaten laden (Close-Preise) für die Rendite-Berechnung\n",
    "df = pd.read_csv(TRAIN_CSV, index_col=0, parse_dates=True).sort_index()\n",
    "close = df[\"close\"].reindex(preds.index)\n",
    "assert close.notna().all(), \"Fehlende Close-Preise im Test-Zeitraum!\"\n",
    "\n",
    "# Den optimierten Threshold aus Block 4 laden\n",
    "# Dieser wurde auf dem Validation-Set bestimmt\n",
    "with open(RUN_DIR/\"evaluation.json\",\"r\") as f:\n",
    "    EVAL = json.load(f)\n",
    "thr = float(EVAL[\"threshold_selection\"][\"threshold\"])\n",
    "\n",
    "# Signale generieren: Alles über Threshold ist ein Kauf-Signal (1)\n",
    "proba_used = preds[\"y_proba_used\"].values\n",
    "signals_t  = (proba_used >= thr).astype(int)\n",
    "\n",
    "# WICHTIG: T+1 Logik!\n",
    "# Wenn wir heute Abend (t) das Signal berechnen (auf Basis des Schlusskurses),\n",
    "# können wir frühestens morgen früh (t+1) kaufen.\n",
    "# Wir schieben die Signale also um 1 Tag in die Zukunft.\n",
    "signals_t1 = pd.Series(signals_t, index=preds.index).shift(1).fillna(0).astype(int).values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c78a0ac9-2b29-42e3-a140-71197d6c56bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === BACKTEST ENGINE ===\n",
    "# Wir implementieren zwei Backtest-Logicen:\n",
    "# A) Realistisch: T+1 Entry, Kosten, Keine Positions-Überlappung.\n",
    "# B) Theoretisch: T0 Entry (Referenz, \"Upper Bound\").\n",
    "\n",
    "def backtest_t1_no_overlap(close: pd.Series, signals, H: int,\n",
    "                           rt_bps: float = 15.0, slip_bps_per_leg: float = 2.0):\n",
    "    \"\"\"\n",
    "    Simuliert realistischen Handel:\n",
    "    - Wir steigen bei Open von Tag t+1 ein (approximiert durch Close t bis Close t+1 Return).\n",
    "    - Wir halten H Tage.\n",
    "    - 'No Overlap': Wenn wir schon investiert sind, ignorieren wir neue Signale, bis wir verkauft haben.\n",
    "      Das vereinfacht das Exposure-Management.\n",
    "    \"\"\"\n",
    "    # Log-Returns des Marktes (tägliche Veränderungen)\n",
    "    r = np.log(close).diff().fillna(0.0).values\n",
    "    \n",
    "    # Gesamtkosten pro Trade (Entry + Exit) als dezimaler Abschlag\n",
    "    # RT-BPS wird halbiert (halbe Gebühr bei Kauf, halbe bei Verkauf) + Slippage jedes Mal\n",
    "    entry_cost = (rt_bps/2.0 + slip_bps_per_leg) / 1e4\n",
    "    exit_cost  = entry_cost\n",
    "\n",
    "    pos = np.zeros_like(r, dtype=int) # Array für Positionen (1=Investiert, 0=Cash)\n",
    "    i = 0\n",
    "    while i < len(r) - 1:\n",
    "        if signals[i] == 1:\n",
    "            # Signal ist da -> Trade startet morgen (i+1)\n",
    "            # Hinweis: signals ist hier schon signals_t1 (verschoben), daher ist i der Einstiegstag\n",
    "            start = i \n",
    "            # Trade endet nach H Tagen (oder am Ende der Daten)\n",
    "            end   = min(i + H - 1, len(r) - 1)\n",
    "            \n",
    "            # Position markieren\n",
    "            pos[start:end+1] = 1 \n",
    "            \n",
    "            # Wir springen direkt zum Ende des Trades (keine neuen Signale währenddessen)\n",
    "            i = end + 1\n",
    "        else:\n",
    "            i += 1\n",
    "\n",
    "    # Rendite berechnen: Markt-Return * Position\n",
    "    net = pos * r\n",
    "    \n",
    "    # Kosten abziehen: Immer wenn sich pos von 0 auf 1 ändert (Entry) oder 1 auf 0 (Exit)\n",
    "    pos_prev = np.r_[0, pos[:-1]]\n",
    "    entries = (pos == 1) & (pos_prev == 0)\n",
    "    exits   = (pos == 0) & (pos_prev == 1)\n",
    "    \n",
    "    # Kosten mindern die Log-Rendite (log(1-cost) ist approx -cost)\n",
    "    net = net + entries * np.log(1 - entry_cost) + exits * np.log(1 - exit_cost)\n",
    "    \n",
    "    # Equity Curve (Kumulierte Rendite) für den Plot\n",
    "    eq = np.exp(np.cumsum(net))\n",
    "    return pd.Series(eq, index=close.index), pd.Series(net, index=close.index), pd.Series(pos, index=close.index)\n",
    "\n",
    "def backtest_t0_upper_bound(close: pd.Series, signals, H: int,\n",
    "                            rt_bps: float = 15.0, slip_bps_per_leg: float = 2.0):\n",
    "    \"\"\"\n",
    "    Optimistisches Szenario:\n",
    "    - Wir handeln SOFORT zum Schlusskurs (t=0), wenn das Signal kommt.\n",
    "    - Das ist in der Praxis fast unmöglich (wir kennen den Schlusskurs erst nach Börsenschluss),\n",
    "      zeigt aber das theoretische Potential des Modells ohne Zeitverzögerung.\n",
    "    \"\"\"\n",
    "    r = np.log(close).diff().fillna(0.0).values\n",
    "    entry_cost = (rt_bps/2.0 + slip_bps_per_leg) / 1e4\n",
    "    exit_cost  = entry_cost\n",
    "\n",
    "    pos = np.zeros_like(r, dtype=int)\n",
    "    i = 0\n",
    "    while i < len(r):\n",
    "        if signals[i] == 1:\n",
    "            start = i  # Sofort rein\n",
    "            end   = min(i + H - 1, len(r) - 1)\n",
    "            pos[start:end+1] = 1\n",
    "            i = end + 1\n",
    "        else:\n",
    "            i += 1\n",
    "\n",
    "    net = pos * r\n",
    "    pos_prev = np.r_[0, pos[:-1]]\n",
    "    entries = (pos == 1) & (pos_prev == 0)\n",
    "    exits   = (pos == 0) & (pos_prev == 1)\n",
    "    net = net + entries * np.log(1 - entry_cost) + exits * np.log(1 - exit_cost)\n",
    "    eq = np.exp(np.cumsum(net))\n",
    "    return pd.Series(eq, index=close.index), pd.Series(net, index=close.index), pd.Series(pos, index=close.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a9e9d937-538c-49a1-b679-dcdb49bac9e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === KPI BERECHNUNG ===\n",
    "# Standard-Funktionen für Finanz-Kennzahlen\n",
    "\n",
    "def _cagr(eq: pd.Series, periods_per_year=252):\n",
    "    # Compound Annual Growth Rate: Jährliche Wachstumsrate\n",
    "    eq = eq.dropna()\n",
    "    if len(eq) < 2: return 0.0\n",
    "    T = len(eq) / periods_per_year\n",
    "    if T < 1e-12: return 0.0\n",
    "    return float((eq.iloc[-1] / eq.iloc[0])**(1.0/T) - 1.0)\n",
    "\n",
    "def _sharpe(net_logrets: pd.Series, periods_per_year=252):\n",
    "    # Sharpe Ratio: Rendite pro Risiko (Standardabweichung)\n",
    "    lr = pd.Series(net_logrets).dropna()\n",
    "    if len(lr) < 2: return 0.0\n",
    "    mu = lr.mean() * periods_per_year\n",
    "    sd = lr.std(ddof=1) * math.sqrt(periods_per_year)\n",
    "    return float(mu / (sd + 1e-12))\n",
    "\n",
    "def _max_dd(eq: pd.Series):\n",
    "    # Maximum Drawdown: Größter Verlust von einem Höchststand (Tal der Tränen)\n",
    "    cum = np.log(eq.values)\n",
    "    peak = np.maximum.accumulate(cum)\n",
    "    dd = np.exp(cum - peak) - 1.0\n",
    "    return float(dd.min())\n",
    "\n",
    "def _exposure(pos: pd.Series):\n",
    "    # Zeitanteil im Markt (Wie oft sind wir investiert?)\n",
    "    return float((pos > 0).mean())\n",
    "\n",
    "def _turnover(pos: pd.Series):\n",
    "    # Umschlagshäufigkeit (Wie oft kaufen/verkaufen wir?) wichtig für Kosten\n",
    "    d = pos.diff().fillna(0).abs()\n",
    "    return float(d.sum())\n",
    "\n",
    "def _trade_stats(net_logrets: pd.Series, pos: pd.Series):\n",
    "    # Detaillierte Analyse pro Trade (Gewinn/Verlust p. Trade)\n",
    "    p = pos.astype(int).values\n",
    "    # Start und Ende der Trades finden\n",
    "    entries = np.where((p == 1) & (np.r_[0, p[:-1]] == 0))[0]\n",
    "    exits   = np.where((p == 0) & (np.r_[0, p[:-1]] == 1))[0] - 1\n",
    "    \n",
    "    # Falls letzter Trade noch offen ist\n",
    "    if len(exits) < len(entries):\n",
    "        exits = np.r_[exits, len(p) - 1]\n",
    "        \n",
    "    pnls = []\n",
    "    for s, e in zip(entries, exits):\n",
    "        if e >= s:\n",
    "            # Summe der Log-Returns im Trade-Zeitraum\n",
    "            pnls.append(float(net_logrets.iloc[s:e+1].sum()))\n",
    "            \n",
    "    if not pnls:\n",
    "        return dict(n_trades=0, hit_rate=None, median=None, iqr=None)\n",
    "        \n",
    "    pnls = np.array(pnls)\n",
    "    hit_rate = float((pnls > 0).mean()) # Trefferquote\n",
    "    q25, q50, q75 = np.percentile(pnls, [25, 50, 75]) # Quartile\n",
    "    return dict(n_trades=int(len(pnls)), hit_rate=hit_rate, median=float(q50), iqr=float(q75 - q25))\n",
    "\n",
    "# Bootstrapping für Signifikanz-Tests\n",
    "# Wir simulieren zufällige Märkte/Trades, um Konfidenzintervalle zu erhalten.\n",
    "def _block_bootstrap_stats(net_logrets: pd.Series, block: int, n=500, seed=42, periods_per_year=252):\n",
    "    rng = np.random.default_rng(seed)\n",
    "    lr = net_logrets.dropna().values\n",
    "    if len(lr) == 0: return {\"CAGR_CI\": [0,0,0], \"Sharpe_CI\": [0,0,0]}\n",
    "    \n",
    "    cagr_vals, sharpe_vals = [], []\n",
    "    idx = np.arange(len(lr))\n",
    "    for _ in range(n):\n",
    "        # Block-Sampling (zieht Blöcke statt einzelner Punkte, erhält Zeitstruktur)\n",
    "        starts = rng.integers(0, max(1, len(idx)-block+1), size=max(1, len(idx)//block))\n",
    "        bs_idx = np.concatenate([np.arange(s, min(s+block, len(idx))) for s in starts])\n",
    "        \n",
    "        lr_bs = lr[bs_idx]\n",
    "        eq_bs = np.exp(np.cumsum(lr_bs))\n",
    "        \n",
    "        # Metrics für diesen Bootstrap-Sample berechnen\n",
    "        T = len(lr_bs) / periods_per_year\n",
    "        if T > 1e-12:\n",
    "             cagr = (eq_bs[-1] / eq_bs[0])**(1.0/T) - 1.0\n",
    "        else:\n",
    "             cagr = 0.0\n",
    "             \n",
    "        mu = lr_bs.mean() * periods_per_year\n",
    "        sd = lr_bs.std(ddof=1) * math.sqrt(periods_per_year)\n",
    "        sh = mu / (sd + 1e-12)\n",
    "        \n",
    "        cagr_vals.append(float(cagr))\n",
    "        sharpe_vals.append(float(sh))\n",
    "        \n",
    "    # Konfidenzintervalle (2.5% - 97.5%)\n",
    "    return {\n",
    "        \"CAGR_CI\": list(np.percentile(cagr_vals, [2.5, 50, 97.5]).astype(float)),\n",
    "        \"Sharpe_CI\": list(np.percentile(sharpe_vals, [2.5, 50, 97.5]).astype(float))\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bbb53ee1-3107-48a2-a20c-49f3a6ed76da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Block 6] Hauptszenario RT=15 bps | Slippage/Leg=2.0 bps\n",
      "Entry@t (Idealisiert/Upper Bound): {'CAGR': 0.26272306523639655, 'Sharpe': 0.7692730097656374, 'MaxDD': -0.22988981699499222, 'final_equity': 1.1922637559932414, 'exposure': 0.7015706806282722, 'turnover': 27.0, 'n_trades': 14, 'hit_rate': 0.5714285714285714, 'median': 0.002984799883910129, 'iqr': 0.05873137719450727}\n",
      "Entry@t+1 (Realistisch):           {'CAGR': 0.21067681484178058, 'Sharpe': 0.6432682814665989, 'MaxDD': -0.22988981699499222, 'final_equity': 1.1559262421020298, 'exposure': 0.7015706806282722, 'turnover': 28.0, 'n_trades': 14, 'hit_rate': 0.6428571428571429, 'median': 0.009170917280172643, 'iqr': 0.041609591832514115}\n",
      "Bootstrap CIs (T+1):               {'CAGR_CI': [0.13141709433989343, 0.40167283070983983, 0.8205011385288256], 'Sharpe_CI': [0.4560743743425412, 2.0251841612798085, 3.3837315100450236]}\n"
     ]
    }
   ],
   "source": [
    "# === 1) HAUPT-SZENARIO AUSWERTEN ===\n",
    "# Wir führen den Backtest mit den Standard-Kosten durch.\n",
    "main_rt = ROUNDTRIP_BPS_DEFAULT\n",
    "\n",
    "# Backtests laufen lassen (hier nutzen wir die verschobenen signals_t1 für den realen Test\n",
    "# und signals_t1 *aber* die T1-Logik erwartet T1-Inputs.\n",
    "# Moment: backtest_t1_no_overlap nimmt \"signals\". Wir haben signals_t1 schon vorab verschoben?\n",
    "# -> In Block 3 haben wir: signals_t1 = shift(1).\n",
    "# -> In backtest_t1_no_overlap(..., signals): if signals[i]==1: start=i. (Da wir schon geshiftet haben, ist i korrekt der morgige Tag)\n",
    "#    Warte, backtest_t1 macht start = i+1.\n",
    "#    Wenn wir signals_t1 übergeben, haben wir doppelt verschoben?\n",
    "#    Check Block 3: signals_t1 ist der Vektor, wo an Index t das Signal für t steht? Nein, shift(1) heißt an Index t steht der Wert von t-1.\n",
    "#    Also an \"heute\" steht das Signal von \"gestern Abend\".\n",
    "#    backtest_t1: \"if signals[i] == 1 ... start = i+1\".\n",
    "#    Das würde bedeuten, wir handeln erst ÜBERMORGEN?\n",
    "#    Korrektur: backtest_t1 ist so gebaut, dass es \"raw signals\" (un-shifted) erwartet und intern auf i+1 entryt.\n",
    "#    ABER hier übergeben wir signals_t1. Das ist riskant.\n",
    "#    Lösung: Wir übergeben 'signals_t' (unshifted) an backtest_t1_no_overlap, das intern i+1 macht.\n",
    "#    ODER wir nutzen signals_t1 und passen die Funktion an.\n",
    "#    Schauen wir auf stats: Wir rufen `backtest_t1_no_overlap(close, signals_t1, ...)` auf.\n",
    "#    Das führt dazu, dass wir bei i ein Signal sehen (was real gestern war) und bei i+1 einsteigen.\n",
    "#    Das ist effektiv T+2. Etwas konservativ, aber sicher.\n",
    "#    (Für die reine Kommentierung ändern wir keine Logik, wir erklären es nur.)\n",
    "\n",
    "# Führen wir die Backtests durch:\n",
    "# T+1 Realistisch (konservativ, evtl. sogar T+2 durch doppelten Shift, was sicher ist)\n",
    "eq_t1, net_t1, pos_t1 = backtest_t1_no_overlap(close, signals_t1, H, main_rt, SLIPPAGE_BPS_PER_LEG)\n",
    "# T+0 Idealisiert (Theoretical Upper Bound)\n",
    "eq_t0, net_t0, pos_t0 = backtest_t0_upper_bound(close, signals_t,  H, main_rt, SLIPPAGE_BPS_PER_LEG)\n",
    "\n",
    "# Statistiken berechnen und zusammenfassen\n",
    "stats_t1 = dict(\n",
    "    CAGR=_cagr(eq_t1), Sharpe=_sharpe(net_t1), MaxDD=_max_dd(eq_t1),\n",
    "    final_equity=float(eq_t1.iloc[-1]),\n",
    "    exposure=_exposure(pos_t1), turnover=_turnover(pos_t1),\n",
    "    **_trade_stats(net_t1, pos_t1)\n",
    ")\n",
    "\n",
    "stats_t0 = dict(\n",
    "    CAGR=_cagr(eq_t0), Sharpe=_sharpe(net_t0), MaxDD=_max_dd(eq_t0),\n",
    "    final_equity=float(eq_t0.iloc[-1]),\n",
    "    exposure=_exposure(pos_t0), turnover=_turnover(pos_t0),\n",
    "    **_trade_stats(net_t0, pos_t0)\n",
    ")\n",
    "\n",
    "# Bootstrap (nur für das realistische Szenario T+1 wichtig, um Zufall auszuschließen)\n",
    "cis = _block_bootstrap_stats(net_t1, block=LOOKBACK, n=400, seed=int(C.get(\"seed\",42)))\n",
    "\n",
    "print(f\"[Block 6] Hauptszenario RT={main_rt:.0f} bps | Slippage/Leg={SLIPPAGE_BPS_PER_LEG:.1f} bps\")\n",
    "print(\"Entry@t (Idealisiert/Upper Bound):\", stats_t0)\n",
    "print(\"Entry@t+1 (Realistisch):          \", stats_t1)\n",
    "print(\"Bootstrap CIs (T+1):              \", cis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "04832b76-b045-483e-86f5-a15ce4cf718b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Sensitivität (bps) – T+1, No-Overlap:\n",
      "                 model  roundtrip_bps  trades  exposure  turnover   CAGR  Sharpe   MaxDD  final_equity\n",
      "Entry@t+1 (No-Overlap)         5.0000      14    0.7016   28.0000 0.2333  0.7053 -0.2299        1.1722\n",
      "Entry@t+1 (No-Overlap)        10.0000      14    0.7016   28.0000 0.2219  0.6743 -0.2299        1.1641\n",
      "Entry@t+1 (No-Overlap)        15.0000      14    0.7016   28.0000 0.2107  0.6433 -0.2299        1.1559\n",
      "Entry@t+1 (No-Overlap)        25.0000      14    0.7016   28.0000 0.1885  0.5811 -0.2299        1.1398\n",
      "Entry@t+1 (No-Overlap)        50.0000      14    0.7016   28.0000 0.1347  0.4254 -0.2299        1.1006\n",
      "Entry@t+1 (No-Overlap)       100.0000      14    0.7016   28.0000 0.0343  0.1132 -0.2299        1.0259\n"
     ]
    }
   ],
   "source": [
    "# === 2) SENSITIVITÄT ÜBER KOSTEN ===\n",
    "# Was passiert, wenn die Kosten höher/niedriger sind?\n",
    "# Wenn die Strategie bei leicht höheren Kosten zusammenbricht, ist sie nicht robust.\n",
    "\n",
    "rows = []\n",
    "for rt in SENSI_BPS:\n",
    "    # Wir testen verschiedene Roundtrip-Kosten durch\n",
    "    eqB, netB, posB = backtest_t1_no_overlap(close, signals_t1, H, rt, SLIPPAGE_BPS_PER_LEG)\n",
    "    tr_stats = _trade_stats(netB, posB)\n",
    "    rows.append(dict(\n",
    "        model=\"Entry@t+1 (No-Overlap)\", \n",
    "        roundtrip_bps=rt,\n",
    "        trades=tr_stats[\"n_trades\"], \n",
    "        exposure=_exposure(posB), \n",
    "        turnover=_turnover(posB),\n",
    "        CAGR=_cagr(eqB), \n",
    "        Sharpe=_sharpe(netB), \n",
    "        MaxDD=_max_dd(eqB), \n",
    "        final_equity=float(eqB.iloc[-1])\n",
    "    ))\n",
    "\n",
    "sensi = pd.DataFrame(rows).sort_values([\"roundtrip_bps\"])\n",
    "sensi_path = RUN_DIR/\"cost_sensitivity.csv\"\n",
    "sensi.to_csv(sensi_path, index=False)\n",
    "\n",
    "print(\"\\nSensitivität (bps) – T+1, No-Overlap:\")\n",
    "print(sensi.to_string(index=False, float_format=lambda x: f\"{x:,.4f}\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5b85fe2a-8edd-417d-8e4b-9545f1cc01df",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === PLOTS: EQUITY CURVES ===\n",
    "# Visualisierung des Kapitalverlaufs.\n",
    "figdir = RUN_DIR/\"figures\"\n",
    "figdir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "plt.figure(figsize=(9,4))\n",
    "# Ideal-Kurve (transparent)\n",
    "plt.plot(eq_t0.index, eq_t0.values,  label=f\"Entry@t (Ideal, {main_rt:.0f}bps)\", alpha=0.6)\n",
    "# Real-Kurve (dick)\n",
    "plt.plot(eq_t1.index, eq_t1.values,  label=f\"Entry@t+1 (Real, {main_rt:.0f}bps)\", linewidth=2)\n",
    "\n",
    "# Buy & Hold als Benchmark (ohne Kosten simuliert, reine Kursentwicklung)\n",
    "bh_log = (np.log(close) - np.log(close.iloc[0])).fillna(0.0)\n",
    "bh_eq  = np.exp(bh_log)\n",
    "plt.plot(eq_t1.index, bh_eq.reindex(eq_t1.index), label=\"Buy & Hold\", linestyle=\"--\", color=\"gray\")\n",
    "\n",
    "plt.title(f\"Equity Curve (H={H}) – Real vs. Ideal\")\n",
    "plt.ylabel(\"Wertentwicklung (Start=1.0)\")\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.savefig(figdir/\"equity_costed.png\", dpi=160)\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ce119634-a95e-49b4-a916-885a427d733a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Block 6 abgeschlossen →\n",
      " - figures/equity_costed.png\n",
      " - cost_sensitivity.csv\n",
      " - evaluation.json (aktualisiert)\n"
     ]
    }
   ],
   "source": [
    "# === ERGEBNIS SPEICHERN ===\n",
    "# Wir hängen die neuen Kostenergebnisse an das evaluation.json an.\n",
    "# Damit haben wir alle wichtigen Metriken an einem Ort.\n",
    "\n",
    "cost_block = {\n",
    "    \"roundtrip_bps_default\": main_rt,\n",
    "    \"slippage_bps_per_leg\": SLIPPAGE_BPS_PER_LEG,\n",
    "    \"upper_bound_entry_t\":  {\"note\": \"nicht handelbar\", **stats_t0},\n",
    "    \"final_kpi_entry_t1\":   {\"note\": \"realistisch, T+1, No-Overlap\", **stats_t1, **cis},\n",
    "    \"sensitivity_csv\": str(sensi_path.as_posix()),\n",
    "    \"equity_costed_png\": str((figdir/\"equity_costed.png\").as_posix())\n",
    "}\n",
    "\n",
    "EVAL[\"backtest_costs\"] = cost_block\n",
    "EVAL.setdefault(\"report_notes\", {})\n",
    "EVAL[\"report_notes\"].update({\n",
    "    \"kpi_basis\": \"entry_t1_no_overlap\",\n",
    "    \"entry_t_is_upper_bound\": True\n",
    "})\n",
    "\n",
    "# Datei überschreiben\n",
    "with open(RUN_DIR/\"evaluation.json\",\"w\") as f:\n",
    "    json.dump(EVAL, f, indent=2)\n",
    "\n",
    "print(\"\\nBlock 6 abgeschlossen →\")\n",
    "print(\" - figures/equity_costed.png\")\n",
    "print(\" - cost_sensitivity.csv\")\n",
    "print(\" - evaluation.json (aktualisiert)\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
