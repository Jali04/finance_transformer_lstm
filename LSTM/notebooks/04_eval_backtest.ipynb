{
 "cells": [
  {
   "cell_type": "raw",
   "id": "5df2c55f-8949-47a2-94b9-bb1bc25587a1",
   "metadata": {},
   "source": [
    "# -----------------------------------------------------\n",
    "# Block 4: Threshold-Tuning, Evaluation, Backtest & Plots\n",
    "# -----------------------------------------------------\n",
    "# Dieses Notebook ist der \"Richter\". Es bewertet das trainierte Modell objektiv.\n",
    "#\n",
    "# Die wichtigsten Schritte:\n",
    "# 1. Test-Umgebung wiederherstellen (Dateien laden, exakte Features und Splits replizieren).\n",
    "# 2. Kalibrierung: Prüfen, ob die Wahrscheinlichkeiten des Modells (z.B. 0.7) auch wirklich\n",
    "#    einer 70%igen Trefferwahrscheinlichkeit entsprechen. Falls nein, korrigieren (Isotonic/Platt).\n",
    "# 3. Threshold-Tuning: Den optimalen Schwellwert finden, ab dem wir \"Kaufen\" signalisieren.\n",
    "#    Das geschieht streng getrennt auf den Validierungsdaten, um Overfitting zu vermeiden.\n",
    "# 4. Finale Evaluation: Anwendung des Thresholds auf die ungesehenen Testdaten.\n",
    "# 5. Einfacher Backtest: Berechnung der Equity Curve (Vermögensentwicklung) einer simplen Strategie."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4c69ddd0-9c11-473b-a3c9-56496d3485ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === SYSTEM & IMPORTS ===\n",
    "# Standard-Bibliotheken\n",
    "import os, sys, json, time, re, glob\n",
    "from pathlib import Path\n",
    "\n",
    "# Datenverarbeitung und Mathe\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Plotting\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Machine Learning Frameworks\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "\n",
    "# Scikit-Learn für Metriken und Kalibrierung\n",
    "from sklearn.metrics import (\n",
    "    roc_curve, auc, precision_recall_curve, average_precision_score, # Kurven und Scores\n",
    "    classification_report, confusion_matrix, # Detail-Berichte\n",
    "    brier_score_loss, # Misst die Qualität der Wahrscheinlichkeiten\n",
    "    balanced_accuracy_score, matthews_corrcoef # Metriken für unbalancierte Klassen\n",
    ")\n",
    "# Tools zur Kalibrierung der Wahrscheinlichkeiten\n",
    "from sklearn.calibration import calibration_curve, IsotonicRegression\n",
    "from sklearn.linear_model import LogisticRegression # Für Platt Scaling\n",
    "\n",
    "# Zum Laden von Objekten (z.B. Scaler)\n",
    "import joblib, yaml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cca0166e-af30-4220-a759-d39d92819921",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === HILFSFUNKTIONEN: LABEL & FILES FINDEN ===\n",
    "# Da wir Experimente mit verschiedenen Labels (Horizonte, Epsilons) machen,\n",
    "# müssen wir robust die richtigen Dateien wiederfinden.\n",
    "\n",
    "# Diese Funktion liest Parameter aus der 'features_v2.yml' (o.ä.)\n",
    "def label_from_yaml(featureset: str):\n",
    "    p = f\"../data/features_{featureset}.yml\"\n",
    "    if os.path.exists(p):\n",
    "        with open(p, \"r\") as f:\n",
    "            meta = yaml.safe_load(f) or {}\n",
    "        # Wir suchen den Abschnitt \"label\"\n",
    "        lab = (meta.get(\"label\") or {})\n",
    "        H  = lab.get(\"horizon\")\n",
    "        md = lab.get(\"mode\")\n",
    "        eps = lab.get(\"epsilon\")\n",
    "        # Wenn alles da ist, geben wir es zurück\n",
    "        if H is not None and md is not None and eps is not None:\n",
    "            return int(H), str(md), float(eps)\n",
    "    return None\n",
    "\n",
    "# Diese Funktion extrahiert Parameter direkt aus Dateinamen wie \"..._cls_h5_abs0p0005.csv\"\n",
    "def parse_h_eps_from_path(path: str):\n",
    "    # Sucht nach \"_cls_h(Zahl)_\"\n",
    "    mH = re.search(r\"_cls_h(\\d+)_\", path)\n",
    "    # Sucht nach Mode und Epsilon am Ende\n",
    "    me = re.search(r\"_(abs|rel|q\\d+\\.\\d+)([\\dp.]+)\\.csv$\", path)\n",
    "    \n",
    "    H = int(mH.group(1)) if mH else None\n",
    "    if me:\n",
    "        mode, eps_str = me.group(1), me.group(2).replace(\"p\", \".\")\n",
    "        return H, mode, float(eps_str)\n",
    "    return H, None, None\n",
    "\n",
    "# Diese Funktion sucht im Datenordner nach der neuesten passenden CSV-Datei\n",
    "def infer_label_from_files(ticker, interval, start, end, H_hint=None, mode_hint=None, eps_hint=None):\n",
    "    # Basis-Muster\n",
    "    pat = f\"../data/{ticker}_{interval}_{start}_{end}_cls_h*_.csv\".replace(\"_ .csv\",\".csv\")\n",
    "    cands = sorted(glob.glob(pat), key=os.path.getmtime)\n",
    "    # Filter: Muss \"_cls_h\" im Namen haben\n",
    "    cands = [c for c in cands if (\"_cls_h\" in c)]\n",
    "    \n",
    "    # Weitere Filter falls Hinweise gegeben sind\n",
    "    if H_hint is not None:\n",
    "        cands = [c for c in cands if f\"_cls_h{H_hint}_\" in c]\n",
    "    if mode_hint and eps_hint is not None:\n",
    "        tag = f\"{mode_hint}{str(eps_hint).replace('.','p')}\"\n",
    "        cands = [c for c in cands if c.endswith(f\"_{tag}.csv\")]\n",
    "        \n",
    "    if not cands:\n",
    "        return None\n",
    "        \n",
    "    # Wir nehmen die neueste Datei\n",
    "    return parse_h_eps_from_path(cands[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "278a7b07-01fd-44f4-8652-467372321368",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Block4] Labels: H=1, mode=abs, epsilon=0.0005\n",
      "RUN_DIR: ..\\results\\2026-01-03_21-02-35_lstm\n"
     ]
    }
   ],
   "source": [
    "# === 1) CONFIG & RUN-DIR BESTIMMEN ===\n",
    "ROOT = os.path.abspath(\"..\")\n",
    "if ROOT not in sys.path: sys.path.insert(0, ROOT)\n",
    "\n",
    "# Config laden\n",
    "with open(os.path.join(ROOT, \"config.json\"), \"r\") as f:\n",
    "    C = json.load(f)\n",
    "\n",
    "TICKER, START, END, INTERVAL = C[\"ticker\"], C[\"start\"], C[\"end\"], C[\"interval\"]\n",
    "LOOKBACK = int(C[\"lookback\"])\n",
    "SEED = int(C.get(\"seed\", 42))\n",
    "FEATURESET = C.get(\"featureset\", \"v2\")\n",
    "\n",
    "# Versuchen, Label-Parameter (H/Mode/Epsilon) zu finden\n",
    "lbl = label_from_yaml(FEATURESET)\n",
    "if lbl is not None:\n",
    "    HORIZON, EPS_MODE, EPSILON = lbl\n",
    "else:\n",
    "    # Fallback: Raten anhand der Dateien im Ordner\n",
    "    HORIZON, EPS_MODE, EPSILON = infer_label_from_files(TICKER, INTERVAL, START, END)\n",
    "    if HORIZON is None or EPS_MODE is None or EPSILON is None:\n",
    "        raise RuntimeError(\"Label-Definition (H/mode/epsilon) konnte nicht bestimmt werden. Block 2 nötig.\")\n",
    "\n",
    "print(f\"[Block4] Labels: H={HORIZON}, mode={EPS_MODE}, epsilon={EPSILON}\")\n",
    "\n",
    "# Seeds setzen\n",
    "np.random.seed(SEED); tf.random.set_seed(SEED)\n",
    "\n",
    "RESULTS_DIR = Path(C.get(\"results_dir\", \"../results\"))\n",
    "\n",
    "# Wir suchen den Run-Ordner, der zu diesen Parametern passt (und am neuesten ist)\n",
    "def _latest_run_dir_matching(results_dir: Path, H: int, eps_mode: str, eps: float) -> Path:\n",
    "    # Der Tag, den wir im Dateinamen erwarten\n",
    "    tag = f\"{eps_mode}{str(eps).replace('.','p')}\"\n",
    "    # Alle LSTM-Runs holen, sortiert nach Datum (neu -> alt)\n",
    "    runs = sorted(results_dir.glob(\"*_lstm\"), key=lambda p: p.stat().st_mtime, reverse=True)\n",
    "    \n",
    "    for r in runs:\n",
    "        cfgp = r / \"config.json\"\n",
    "        if not cfgp.exists(): continue\n",
    "        try:\n",
    "            with open(cfgp, \"r\") as f:\n",
    "                rcfg = json.load(f)\n",
    "            \n",
    "            # Prüfung: Stimmen Lookback, Horizon und Epsilon überein?\n",
    "            ok_lb = int(rcfg.get(\"lookback\", LOOKBACK)) == LOOKBACK\n",
    "            ok_h  = (int(rcfg.get(\"horizon\", H)) == H) or ((\"_cls_h\"+str(H)+\"_\") in str(rcfg.get(\"train_csv\",\"\")))\n",
    "            ok_eps= (tag in str(rcfg.get(\"train_csv\",\"\")))\n",
    "            \n",
    "            if ok_lb and ok_h and ok_eps:\n",
    "                return r # Das ist unser Ordner!\n",
    "        except Exception:\n",
    "            pass\n",
    "            \n",
    "    # Wenn wir keinen perfekten Match finden, nehmen wir zur Not den allerneuesten.\n",
    "    if runs:\n",
    "        print(\"[WARN] Kein exakter Match gefunden, nehme neuesten Run.\")\n",
    "        return runs[0]\n",
    "        \n",
    "    raise FileNotFoundError(\"Kein RUN_DIR gefunden – bitte Block 3 trainieren.\")\n",
    "\n",
    "RUN_DIR = _latest_run_dir_matching(RESULTS_DIR, HORIZON, EPS_MODE, EPSILON)\n",
    "print(\"RUN_DIR:\", RUN_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "70085932-0e7c-4267-a84a-55b823b98d9b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Artefakte gefunden.\n"
     ]
    }
   ],
   "source": [
    "# === 2) ARTEFAKTE LADEN (Model, Scaler, Config) ===\n",
    "# Wir stellen die Trainingsumgebung wieder her.\n",
    "\n",
    "ENV_INFO = RUN_DIR / \"env_info.json\"\n",
    "MODEL_PATH = RUN_DIR / \"model.keras\"\n",
    "BEST_PATH  = RUN_DIR / \"best.keras\" # Das ist der Checkpoint (bestes Val-Ergebnis)\n",
    "SCALER_PATH = RUN_DIR / \"scaler.joblib\"\n",
    "CFG_PATH    = RUN_DIR / \"config.json\"\n",
    "\n",
    "# Wir bevorzugen 'best.keras', da 'model.keras' oft nur das Modell der allerletzten Epoche ist (Overfitting-Gefahr).\n",
    "if BEST_PATH.exists():\n",
    "    MODEL_PATH = BEST_PATH\n",
    "\n",
    "# Sicherheitschecks\n",
    "assert MODEL_PATH.exists(), f\"Model-File fehlt: {MODEL_PATH}\"\n",
    "assert SCALER_PATH.exists(), f\"Scaler-File fehlt: {SCALER_PATH}\"\n",
    "assert CFG_PATH.exists(),    f\"Run-Config fehlt: {CFG_PATH}\"\n",
    "\n",
    "# Config einlesen\n",
    "with open(CFG_PATH, \"r\") as f:\n",
    "    RCFG = json.load(f)\n",
    "\n",
    "print(\"Artefakte gefunden.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e61e4baf-7d92-4cc9-b8c3-23210146cd05",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer gru will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer gru_1 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "Model und Scaler geladen.\n"
     ]
    }
   ],
   "source": [
    "# === 3) KONSISTENZPRÜFUNG & MODELL-LOAD ===\n",
    "# Bevor es losgeht, checken wir nochmal, ob die Parameter zusammenpassen.\n",
    "\n",
    "def _parse_h_mode_eps_from_train_csv(path: str):\n",
    "    mH = re.search(r\"_cls_h(\\d+)_\", path)\n",
    "    me = re.search(r\"_(abs|rel|q\\d+\\.\\d+)([\\dp.]+)\\.csv$\", path)\n",
    "    H = int(mH.group(1)) if mH else None\n",
    "    mode = me.group(1) if me else None\n",
    "    eps = float(me.group(2).replace(\"p\",\".\")) if me else None\n",
    "    return H, mode, eps\n",
    "\n",
    "run_h_cfg = int(RCFG.get(\"horizon\", HORIZON))\n",
    "run_lb    = int(RCFG.get(\"lookback\", LOOKBACK))\n",
    "train_csv_in_cfg = str(RCFG.get(\"train_csv\", \"\"))\n",
    "\n",
    "h_from_name, mode_from_name, eps_from_name = _parse_h_mode_eps_from_train_csv(train_csv_in_cfg)\n",
    "\n",
    "# Wenn der Lookback nicht passt, würde das Modell technisch nicht funktionieren (falsche Input-Shape).\n",
    "assert run_lb == LOOKBACK, f\"Inkompatibler Lookback: run={run_lb} vs. core={LOOKBACK}\"\n",
    "\n",
    "# Warnungen bei kleineren Diskrepanzen (wir brechen nicht hart ab, aber geben Info)\n",
    "ok_h  = (run_h_cfg == HORIZON) or (h_from_name == HORIZON)\n",
    "ok_m  = (mode_from_name is None) or (mode_from_name == EPS_MODE)\n",
    "ok_e  = (eps_from_name  is None) or (np.isclose(eps_from_name, EPSILON))\n",
    "\n",
    "if not (ok_h and ok_m and ok_e):\n",
    "    print(\"[WARN] Run-Config uneindeutig zu Label-Definition, fahre trotzdem fort.\")\n",
    "\n",
    "# Modell laden (ohne Kompilierung, da wir nur Predicten wollen, nicht Trainieren)\n",
    "model  = keras.models.load_model(MODEL_PATH, compile=False)\n",
    "# Scaler laden\n",
    "scaler = joblib.load(SCALER_PATH)\n",
    "\n",
    "print(\"Model und Scaler geladen.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "823511f8-37a8-45ef-b581-8afa6625874a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN_CSV: ../data/AAPL_1d_2010-01-01_2026-01-01_cls_h1_abs0p0005.csv\n"
     ]
    }
   ],
   "source": [
    "# === 4) ORIGINAL-DATEN LADEN ===\n",
    "# Wir laden wieder die Feature-CSV, um Testdaten zu generieren.\n",
    "eps_tag = f\"{EPS_MODE}{str(EPSILON).replace('.','p')}\"\n",
    "train_exact = f\"../data/{TICKER}_{INTERVAL}_{START}_{END}_cls_h{HORIZON}_{eps_tag}.csv\"\n",
    "\n",
    "if not os.path.exists(train_exact):\n",
    "    # Fallback Suche nach Datei, falls der genaue Name abweicht\n",
    "    pat = f\"../data/{TICKER}_{INTERVAL}_{START}_{END}_cls_h{HORIZON}_{eps_tag}.csv\"\n",
    "    cands = sorted(glob.glob(pat), key=os.path.getmtime)\n",
    "    if not cands:\n",
    "        raise FileNotFoundError(f\"Train CSV nicht gefunden: {train_exact}\")\n",
    "    TRAIN_CSV = cands[-1]\n",
    "else:\n",
    "    TRAIN_CSV = train_exact\n",
    "\n",
    "print(\"TRAIN_CSV:\", TRAIN_CSV)\n",
    "# Daten laden\n",
    "df = pd.read_csv(TRAIN_CSV, index_col=0, parse_dates=True).sort_index()\n",
    "\n",
    "# Konsistenzcheck: Stimmt der Lookback in der Config?\n",
    "if int(RCFG.get(\"lookback\", LOOKBACK)) != LOOKBACK:\n",
    "    raise AssertionError(\"Inkompatibler Lookback!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c5efa39e-b149-4c17-ba76-cf9cbb384b37",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === 5) FEATURE-SET BESTIMMEN ===\n",
    "# Wir müssen exakt dieselben Features nutzen wie beim Training.\n",
    "if \"features\" in RCFG and RCFG[\"features\"]:\n",
    "    # Wenn die Liste im Config-JSON steht, nehmen wir sie von dort.\n",
    "    FEATURES = [c for c in RCFG[\"features\"] if c in df.columns]\n",
    "else:\n",
    "    # Sonst laden wir sie aus der YAML.\n",
    "    with open(f\"../data/features_{FEATURESET}.yml\",\"r\") as f:\n",
    "        meta = yaml.safe_load(f) or {}\n",
    "    FEATURES = [c for c in meta.get(\"features\", []) if c in df.columns]\n",
    "\n",
    "assert len(FEATURES) > 0, \"Keine Features gefunden!\"\n",
    "\n",
    "X = df[FEATURES].copy()\n",
    "y = df[\"target\"].astype(int).copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "24824a33-b6a3-4b61-b363-2551d40fda8c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Split sizes: Train=3489 Val=252 Test=250\n"
     ]
    }
   ],
   "source": [
    "# === 6) SPLIT WIEDERHERSTELLEN ===\n",
    "# Wir nutzen exakt denselben Datums-Split wie im Training (Block 3).\n",
    "\n",
    "# Train: Alles VOR 2024\n",
    "train_mask = df.index < \"2024-01-01\"\n",
    "# Validation: Das Jahr 2024\n",
    "val_mask   = (df.index >= \"2024-01-01\") & (df.index < \"2025-01-01\")\n",
    "# Test: Das Jahr 2025\n",
    "test_mask  = df.index >= \"2025-01-01\"\n",
    "\n",
    "# Daten aufteilen\n",
    "X_train, y_train = X.loc[train_mask], y.loc[train_mask]\n",
    "X_val,   y_val   = X.loc[val_mask],   y.loc[val_mask]\n",
    "X_test,  y_test  = X.loc[test_mask],  y.loc[test_mask]\n",
    "\n",
    "print(f\"Split sizes: Train={len(X_train)} Val={len(X_val)} Test={len(X_test)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6584d486-4b95-4f2c-a270-0fd2c5fc839a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === 7) SKALIERUNG ANWENDEN ===\n",
    "# WICHTIG: Wir nutzen scaler.transform, NICHT fit_transform.\n",
    "# Der Scaler wurde auf Train \"gelernt\" und muss nun stur angewendet werden.\n",
    "X_train_s = pd.DataFrame(scaler.transform(X_train), index=X_train.index, columns=FEATURES)\n",
    "X_val_s   = pd.DataFrame(scaler.transform(X_val),   index=X_val.index,   columns=FEATURES)\n",
    "X_test_s  = pd.DataFrame(scaler.transform(X_test),  index=X_test.index,  columns=FEATURES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9aebd466-487b-4b3f-b3c5-f3dad3a88c6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === 8) WINDOWING (Zeitreihen erstellen) ===\n",
    "# Dieselbe Funktion wie in Block 3 zur Erstellung der Sequenzen.\n",
    "def make_windows(X_df, y_ser, lookback):\n",
    "    Xv = X_df.values.astype(np.float32)\n",
    "    yv = y_ser.values.astype(np.int32)\n",
    "    xs, ys, idx_end = [], [], []\n",
    "    for i in range(lookback-1, len(X_df)):\n",
    "        xs.append(Xv[i - lookback + 1 : i + 1])\n",
    "        ys.append(yv[i])\n",
    "        idx_end.append(X_df.index[i]) # Wir speichern das Datum des Labels für den Backtest\n",
    "    return np.stack(xs, 0), np.array(ys), pd.DatetimeIndex(idx_end)\n",
    "\n",
    "Xtr_win, ytr, idx_tr = make_windows(X_train_s, y_train, LOOKBACK)\n",
    "Xva_win, yva, idx_va = make_windows(X_val_s,   y_val,   LOOKBACK)\n",
    "Xte_win, yte, idx_te = make_windows(X_test_s,  y_test,  LOOKBACK)\n",
    "\n",
    "# Dataset erstellen für effiziente Prediction\n",
    "def to_ds(X, y, batch, shuffle):\n",
    "    ds = tf.data.Dataset.from_tensor_slices((X, y))\n",
    "    # Kein Shuffle bei Test! Reihenfolge ist wichtig.\n",
    "    if shuffle: ds = ds.shuffle(len(X), seed=SEED)\n",
    "    return ds.batch(int(C.get(\"batch\", 64))).prefetch(tf.data.AUTOTUNE)\n",
    "\n",
    "ds_val  = to_ds(Xva_win, yva, int(C.get(\"batch\",64)), shuffle=False)\n",
    "ds_test = to_ds(Xte_win, yte, int(C.get(\"batch\",64)), shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c71bb7ef-7955-4b2f-b901-68f04327ec44",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predictions fertig.\n"
     ]
    }
   ],
   "source": [
    "# === 9) VORHERSAGEN (PREDICTION) ===\n",
    "# Das Modell gibt Wahrscheinlichkeiten aus (0 bis 1).\n",
    "y_val_proba  = model.predict(ds_val,  verbose=0).ravel()\n",
    "y_test_proba = model.predict(ds_test, verbose=0).ravel()\n",
    "\n",
    "print(\"Predictions fertig.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8f1ac0c3-a5b9-4799-bff4-7eff4450611f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === 10) KALIBRIERUNG PRÜFEN ===\n",
    "# Oft sind die Outputs von neuronalen Netzen nicht gut kalibriert.\n",
    "# Beispiel: Wenn das Modell 0.8 sagt, sollte auch in 80% der Fälle ein Treffer vorliegen.\n",
    "# Wir testen zwei Kalibrierungsmethoden: Isotonic Regression und Platt Scaling.\n",
    "\n",
    "# a) Isotonic Regression (flexibel, aber braucht mehr Daten)\n",
    "iso = IsotonicRegression(out_of_bounds=\"clip\").fit(y_val_proba, yva)\n",
    "val_iso  = iso.transform(y_val_proba)\n",
    "test_iso = iso.transform(y_test_proba)\n",
    "\n",
    "# b) Platt Scaling (Logistische Regression auf den Scores)\n",
    "platt = LogisticRegression(max_iter=1000)\n",
    "platt.fit(y_val_proba.reshape(-1,1), yva)\n",
    "val_platt  = platt.predict_proba(y_val_proba.reshape(-1,1))[:,1]\n",
    "test_platt = platt.predict_proba(y_test_proba.reshape(-1,1))[:,1]\n",
    "\n",
    "# Wir messen den \"Brier Score Loss\" (ähnlich MSE für Wahrscheinlichkeiten).\n",
    "# Je kleiner, desto besser.\n",
    "brier_val_raw   = brier_score_loss(yva, y_val_proba)\n",
    "brier_val_iso   = brier_score_loss(yva, val_iso)\n",
    "brier_val_platt = brier_score_loss(yva, val_platt)\n",
    "\n",
    "# Wir wählen den Kandidaten, der auf VALIDATION am besten ist.\n",
    "if brier_val_platt <= brier_val_iso:\n",
    "    cand_name, val_cand, test_cand, cand_obj = \"platt\", val_platt, test_platt, platt\n",
    "    brier_val_cand = brier_val_platt\n",
    "else:\n",
    "    cand_name, val_cand, test_cand, cand_obj = \"isotonic\", val_iso, test_iso, iso\n",
    "    brier_val_cand = brier_val_iso"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c12c8596-1e24-4d3d-b294-2578e6f34274",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Kalibrierung] chosen=isotonic | ΔBrier(VAL)=354.4 bp | Test Brier raw→cand 0.2598→0.2543\n"
     ]
    }
   ],
   "source": [
    "# === 11) KALIBRIERUNG ENTSCHEIDEN ===\n",
    "# Lohnt sich die Kalibrierung? \n",
    "# Wir verlangen eine Mindestverbesserung (min_gain_bp), sonst nehmen wir lieber die Rohdaten (weniger Komplexität).\n",
    "\n",
    "min_gain_bp = 1.0  # 1 Basispunkt (0.0001)\n",
    "gain_bp = (brier_val_raw - brier_val_cand) * 1e4\n",
    "\n",
    "# Nur zur Info: Wie performen sie auf Test? (Darf Entscheidung nicht beeinflussen!)\n",
    "brier_test_raw  = brier_score_loss(yte, y_test_proba)\n",
    "brier_test_cand = brier_score_loss(yte, test_cand)\n",
    "\n",
    "use_cal = (brier_val_raw - brier_val_cand) > 1e-4\n",
    "if use_cal:\n",
    "    # Wir nutzen die Kalibrierung\n",
    "    CAL_METHOD, y_val_cal, y_test_cal = cand_name, val_cand, test_cand\n",
    "    # Speichern für später\n",
    "    joblib.dump(cand_obj, RUN_DIR / f\"calibrator_{CAL_METHOD}.joblib\")\n",
    "    brier_cal = brier_test_cand\n",
    "else:\n",
    "    # Keine Kalibrierung\n",
    "    CAL_METHOD, y_val_cal, y_test_cal = \"none\", y_val_proba, y_test_proba\n",
    "    brier_cal = brier_test_raw\n",
    "\n",
    "print(f\"[Kalibrierung] chosen={CAL_METHOD} | ΔBrier(VAL)={gain_bp:.1f} bp \"\n",
    "      f\"| Test Brier raw→cand {brier_test_raw:.4f}→{brier_test_cand:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "044f863e-5335-4c87-b4ed-079c27b30794",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gewählter Threshold: 0.5000 (Validation MCC: 0.000)\n"
     ]
    }
   ],
   "source": [
    "# === 12) OPTIMALEN THRESHOLD FINDEN ===\n",
    "# Standard-Schwellwert ist 0.5. Das funktioniert aber nur bei perfekt balancierten Daten gut.\n",
    "# Wir optimieren den Threshold auf den Validation-Daten, um den MCC zu maximieren.\n",
    "# MCC ist eine robuste Metrik, die auch bei unbalancierten Klassen gut funktioniert.\n",
    "\n",
    "def choose_threshold(y_true, y_prob, pos_rate_bounds=(0.45,0.55)):\n",
    "    # Wir testen alle vorkommenden Wahrscheinlichkeiten als potentielle Thresholds\n",
    "    uniq = np.unique(y_prob); cand = np.r_[0.0, uniq, 1.0]\n",
    "    best_t, best_s = 0.5, -1.0\n",
    "    \n",
    "    for t in cand:\n",
    "        yp = (y_prob >= t).astype(int)\n",
    "        pr = float(yp.mean()) # Positive Rate (Wie oft sagen wir \"Kaufen\"?)\n",
    "        \n",
    "        # Wir wollen keine Extreme (nie handeln oder immer handeln), daher Bounds.\n",
    "        if not (pos_rate_bounds[0] <= pr <= pos_rate_bounds[1]):\n",
    "            continue\n",
    "        \n",
    "        s = matthews_corrcoef(y_true, yp)\n",
    "        if s > best_s: best_s, best_t = float(s), float(t)\n",
    "            \n",
    "    if best_s < 0:\n",
    "        return 0.5, 0.0 # Fallback\n",
    "    return best_t, best_s\n",
    "\n",
    "# Wir geben enge Grenzen um die tatsächliche Positive-Rate vor.\n",
    "p_val = float(yva.mean())\n",
    "bounds = (max(0.0, p_val - 0.10), min(1.0, p_val + 0.10))\n",
    "\n",
    "# Suche auf Validationset\n",
    "thr, score_val = choose_threshold(yva, y_val_cal, pos_rate_bounds=bounds)\n",
    "\n",
    "# Nur zur Info: Was wäre ungebunden (ohne Bounds) oder mit Youden's J passiert?\n",
    "# (Lassen wir hier im Code stehen, nutzen es aber nicht für die Entscheidung)\n",
    "def best_mcc_unbounded(y_true, y_prob):\n",
    "    # ... (vereinfachte Version)\n",
    "    return 0.0, 0.0 \n",
    "\n",
    "mcc_raw = 0.0; thr_mcc_raw = 0.0; J_raw = 0.0; thr_J_raw = 0.0 # Platzhalter\n",
    "print(f\"Gewählter Threshold: {thr:.4f} (Validation MCC: {score_val:.3f})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "df77d65d-26fe-4609-898c-800dee5c857d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion matrix (test):\n",
      " [[ 0 92]\n",
      " [ 0 99]]\n",
      "MCC=0.000 | BalAcc=0.500 | AUROC=0.500 | AUPRC=0.518 (baseline=0.518) | thr=0.500 | pred_pos_rate(test)=1.000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\jacin\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1731: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n",
      "c:\\Users\\jacin\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1731: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n",
      "c:\\Users\\jacin\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1731: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n"
     ]
    }
   ],
   "source": [
    "# === 13) FINALE TEST-EVALUATION (@ chosen Threshold) ===\n",
    "# Jetzt wird es ernst: Wir wenden den gewählten Threshold auf die Testdaten an.\n",
    "\n",
    "y_test_pred = (y_test_cal >= thr).astype(int)\n",
    "\n",
    "# Confusion Matrix: TP, TN, FP, FN\n",
    "cm   = confusion_matrix(yte, y_test_pred)\n",
    "\n",
    "# Classification Report: Precision, Recall, F1\n",
    "rep  = classification_report(yte, y_test_pred, digits=3, output_dict=True)\n",
    "\n",
    "# AUCs (Area Under Curve) - wichtig unabhängig vom Threshold\n",
    "fpr, tpr, _ = roc_curve(yte, y_test_cal); roc_auc = auc(fpr, tpr)\n",
    "prec, rec, _ = precision_recall_curve(yte, y_test_cal); ap = average_precision_score(yte, y_test_cal)\n",
    "\n",
    "# Baseline für PR-AUC ist die \"Naive\" Wahrscheinlichkeit (einfach raten)\n",
    "ap_baseline_test = float(yte.mean())\n",
    "\n",
    "# Diverse Metriken\n",
    "bal_acc = balanced_accuracy_score(yte, y_test_pred)\n",
    "mcc     = matthews_corrcoef(yte, y_test_pred)\n",
    "pos_rate_test = float(y_test_pred.mean())\n",
    "\n",
    "# Ausgabe\n",
    "print(\"Confusion matrix (test):\\n\", cm)\n",
    "print(f\"MCC={mcc:.3f} | BalAcc={bal_acc:.3f} | AUROC={roc_auc:.3f} | \"\n",
    "      f\"AUPRC={ap:.3f} (baseline={ap_baseline_test:.3f}) | \"\n",
    "      f\"thr={thr:.3f} | pred_pos_rate(test)={pos_rate_test:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e1404cda-f83e-43b6-8e8b-e31d868a1ae7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MCC Bootstrap CI [2.5, 50, 97.5]: [0.0, 0.0, 0.0]\n"
     ]
    }
   ],
   "source": [
    "# === 14) BOOTSTRAP KONFIDENZINTREVALL (MCC) ===\n",
    "# Ein einzelner Wert (z.B. MCC=0.02) sagt wenig aus. Ist das Glück oder Können?\n",
    "# Wir nutzen Bootstrapping, um ein Konfidenzintervall zu berechnen.\n",
    "# Dabei sampeln wir Blöcke aus den Testdaten (um Zeitstruktur zu erhalten) und messen MCC erneut.\n",
    "\n",
    "rng = np.random.default_rng(SEED)\n",
    "def block_bootstrap_mcc(y_true, y_prob, threshold, n=300, block=LOOKBACK):\n",
    "    idx = np.arange(len(y_true))\n",
    "    scores = []\n",
    "    for _ in range(n):\n",
    "        # Wir ziehen zufällige Startpunkte für Blöcke\n",
    "        starts = rng.integers(0, max(1, len(idx)-block+1), size=max(1, len(idx)//block))\n",
    "        # Wir bauen einen neuen \"zusammengewürfelten\" Datensatz\n",
    "        bs = np.concatenate([np.arange(s, min(s+block, len(idx))) for s in starts])\n",
    "        \n",
    "        # Wir berechnen MCC auf diesem Sample\n",
    "        yp = (y_prob[bs] >= threshold).astype(int)\n",
    "        scores.append(matthews_corrcoef(y_true[bs], yp))\n",
    "        \n",
    "    # Wir geben das 2.5%, 50% (Median) und 97.5% Quantil zurück\n",
    "    return np.percentile(scores, [2.5, 50, 97.5]).astype(float)\n",
    "\n",
    "mcc_ci = block_bootstrap_mcc(yte, y_test_cal, thr, n=300, block=LOOKBACK)\n",
    "print(\"MCC Bootstrap CI [2.5, 50, 97.5]:\", [round(x,3) for x in mcc_ci])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "262a19eb-6fcf-415c-80ae-3eb318ce44dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === 15) DIAGNOSE-PLOTS SPEICHERN ===\n",
    "# Visualisierung ist wichtig. Wir speichern Plots im 'figures' Unterordner.\n",
    "FIG_DIR = RUN_DIR / \"figures\"; FIG_DIR.mkdir(exist_ok=True, parents=True)\n",
    "\n",
    "# 1. ROC Curve\n",
    "plt.figure(figsize=(6,4)); plt.plot(fpr, tpr, label=f\"AUC={roc_auc:.3f}\")\n",
    "plt.plot([0,1],[0,1],\"--\"); plt.xlabel(\"FPR\"); plt.ylabel(\"TPR\"); plt.title(\"ROC (Test)\")\n",
    "plt.legend(); plt.tight_layout(); plt.savefig(FIG_DIR / \"roc_test.png\", dpi=160); plt.close()\n",
    "\n",
    "# 2. Precision-Recall Curve\n",
    "plt.figure(figsize=(6,4))\n",
    "plt.plot(rec, prec, label=f\"AP={ap:.3f} (base={ap_baseline_test:.3f})\")\n",
    "plt.hlines(ap_baseline_test, xmin=0, xmax=1, linestyles=\"--\", label=\"Random baseline\")\n",
    "plt.xlabel(\"Recall\"); plt.ylabel(\"Precision\"); plt.title(\"Precision-Recall (Test)\")\n",
    "plt.legend(); plt.tight_layout(); plt.savefig(FIG_DIR / \"pr_test.png\", dpi=160); plt.close()\n",
    "\n",
    "# 3. Kalibrierungskurve\n",
    "prob_true, prob_pred = calibration_curve(yte, y_test_cal, n_bins=10, strategy=\"quantile\")\n",
    "plt.figure(figsize=(6,4)); plt.plot([0,1],[0,1],\"--\"); plt.plot(prob_pred, prob_true, marker=\"o\")\n",
    "plt.xlabel(\"Vorhergesagt\"); plt.ylabel(\"Tatsächlich\"); plt.title(f\"Kalibrierung (Test) – {CAL_METHOD}\")\n",
    "plt.tight_layout(); plt.savefig(FIG_DIR / \"calibration_test.png\", dpi=160); plt.close()\n",
    "\n",
    "# 4. Confusion Matrix\n",
    "plt.figure(figsize=(4.8,4.2))\n",
    "plt.imshow(cm, interpolation=\"nearest\"); plt.title(\"Confusion Matrix (Test)\"); plt.colorbar()\n",
    "ticks = np.arange(2); plt.xticks(ticks, [\"0\",\"1\"]); plt.yticks(ticks, [\"0\",\"1\"])\n",
    "for i in range(cm.shape[0]):\n",
    "    for j in range(cm.shape[1]):\n",
    "        plt.text(j, i, cm[i, j], ha=\"center\", va=\"center\")\n",
    "plt.xlabel(\"Predicted\"); plt.ylabel(\"True\")\n",
    "plt.tight_layout(); plt.savefig(FIG_DIR / \"cm_test.png\", dpi=160); plt.close()\n",
    "\n",
    "# 5. Wahrscheinlichkeits-Histogramm\n",
    "plt.figure(figsize=(6,4))\n",
    "plt.hist(y_test_proba, bins=30, alpha=0.6, label=\"raw\")\n",
    "plt.hist(y_test_cal,   bins=30, alpha=0.6, label=f\"used ({CAL_METHOD})\")\n",
    "plt.axvline(thr, linestyle=\"--\", label=f\"thr={thr:.3f}\")\n",
    "plt.title(\"P(y=1) – raw vs. used (Test)\")\n",
    "plt.legend(); plt.tight_layout()\n",
    "plt.savefig(FIG_DIR / \"proba_hist_raw_vs_used.png\", dpi=160); plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "08cfd2af-70a6-4187-ab6f-c0ffb4d3c9a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === 16) VORHERSAGEN SPEICHERN ===\n",
    "# Wir speichern die Vorhersagen CSV, falls wir sie extern analysieren wollen.\n",
    "preds_test = pd.DataFrame({\n",
    "    \"timestamp\": idx_te, \"y_true\": yte,\n",
    "    \"y_proba_raw\": y_test_proba, \"y_proba_used\": y_test_cal, \"y_pred\": y_test_pred,\n",
    "}).set_index(\"timestamp\")\n",
    "preds_test.to_csv(RUN_DIR / \"preds_test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ac31e9e3-bb48-4f08-b07b-01adcb99f752",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === 17) EINFACHER BACKTEST (Equity Curves) ===\n",
    "# Wir simulieren den Erfolg einer Handelsstrategie basierend auf unseren Signalen.\n",
    "\n",
    "# Reale Kursbewegungen (Log-Returns) für Horizon H\n",
    "close = df[\"close\"].copy()\n",
    "fwd_logret = (np.log(close.shift(-HORIZON)) - np.log(close)).reindex(idx_te)\n",
    "\n",
    "# Wann handeln wir?\n",
    "signals_t  = (preds_test[\"y_proba_used\"] >= thr).astype(int).reindex(idx_te)\n",
    "\n",
    "# Realistische Annahme (t+1): Wir bekommen das Signal heute Abend (t) und kaufen morgen früh (t+1).\n",
    "signals_t1 = signals_t.shift(1).fillna(0) \n",
    "\n",
    "# Strategie-Rendite = Signal * Markt-Rendite\n",
    "strategy_logret_t  = (signals_t  * fwd_logret).fillna(0)\n",
    "strategy_logret_t1 = (signals_t1 * fwd_logret).fillna(0)\n",
    "\n",
    "# Kumulierte Rendite (Equity Curve)\n",
    "equity_t  = strategy_logret_t.cumsum().apply(np.exp) \n",
    "equity_t1 = strategy_logret_t1.cumsum().apply(np.exp)\n",
    "\n",
    "# Vergleich: Buy & Hold (Einfach halten)\n",
    "bh_logret = (np.log(close.reindex(idx_te)) - np.log(close.reindex(idx_te).iloc[0])).fillna(0)\n",
    "bh_equity = np.exp(bh_logret)\n",
    "\n",
    "# KPIs für den Vergleich\n",
    "def _sharpe(logrets, periods_per_year=252):\n",
    "    # Sharpe Ratio: Rendite pro Risiko\n",
    "    mu = logrets.mean() * periods_per_year\n",
    "    sigma = logrets.std(ddof=1) * np.sqrt(periods_per_year)\n",
    "    return float(mu / (sigma + 1e-12))\n",
    "\n",
    "def _cagr(eq, periods_per_year=252):\n",
    "    # CAGR: Jährliche Wachstumsrate\n",
    "    T = len(eq) / periods_per_year\n",
    "    return float((eq.iloc[-1] / eq.iloc[0])**(1.0/max(T,1e-12)) - 1.0)\n",
    "\n",
    "backtest = {\n",
    "    \"n_trades\": int(signals_t.sum()),\n",
    "    \"avg_holding_h\": HORIZON,\n",
    "    \"strategy_t\":  {\"CAGR\": _cagr(equity_t),  \"Sharpe\": _sharpe(strategy_logret_t.dropna()),  \"final_equity\": float(equity_t.iloc[-1])},\n",
    "    \"strategy_t1\": {\"CAGR\": _cagr(equity_t1), \"Sharpe\": _sharpe(strategy_logret_t1.dropna()), \"final_equity\": float(equity_t1.iloc[-1])},\n",
    "    \"buy_hold\":    {\"CAGR\": _cagr(bh_equity), \"final_equity\": float(bh_equity.iloc[-1])},\n",
    "}\n",
    "\n",
    "# Plot speichern\n",
    "plt.figure(figsize=(8,4))\n",
    "plt.plot(equity_t.index, equity_t.values,   label=\"Entry@t (Sofort - unrealistisch)\")\n",
    "plt.plot(equity_t1.index, equity_t1.values, label=\"Entry@t+1 (Verzögert - realistisch)\")\n",
    "plt.plot(bh_equity.index, bh_equity.values, label=\"Buy & Hold\", linestyle=\"--\")\n",
    "plt.title(f\"Equity Curves (H={HORIZON})\")\n",
    "plt.legend(); plt.tight_layout(); plt.savefig(FIG_DIR / \"equity_curves_t_vs_t1.png\", dpi=160); plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "200036f8-d7ff-41fe-aa6f-ae6903888710",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Block 4 abgeschlossen. Ergebnisse:\n",
      " - ..\\results\\2026-01-03_21-02-35_lstm\\evaluation.json\n",
      " - ..\\results\\2026-01-03_21-02-35_lstm\\figures\n"
     ]
    }
   ],
   "source": [
    "# === 18) ALLES ZUSAMMENFASSEN & SPEICHERN ===\n",
    "# Wir sammeln alle Ergebnisse in einer JSON-Datei.\n",
    "\n",
    "out = {\n",
    "    \"config\": RCFG,\n",
    "    \"features_used\": FEATURES,\n",
    "    \"calibration\": {\n",
    "        \"chosen\": CAL_METHOD,\n",
    "        \"val_brier\": {\"raw\": float(brier_val_raw), \"iso\": float(brier_val_iso), \"platt\": float(brier_val_platt)},\n",
    "    },\n",
    "    \"threshold_selection\": {\n",
    "        \"strategy\": \"max_mcc_with_pos_rate_bounds_centered_on_val_rate\",\n",
    "        \"threshold\": float(thr),\n",
    "        \"val_mcc\": float(score_val),\n",
    "    },\n",
    "    \"metrics\": {\n",
    "        \"test\": {\n",
    "            \"roc_auc\": float(roc_auc),\n",
    "            \"balanced_accuracy\": float(bal_acc),\n",
    "            \"auprc\": float(ap),\n",
    "            \"brier\": float(brier_cal),\n",
    "            \"mcc\": float(mcc),\n",
    "            \"report\": rep\n",
    "        },\n",
    "        \"mcc_bootstrap_ci\": [float(x) for x in mcc_ci.tolist()]\n",
    "    },\n",
    "    \"backtest\": backtest\n",
    "}\n",
    "\n",
    "with open(RUN_DIR / \"evaluation.json\", \"w\") as f:\n",
    "    json.dump(out, f, indent=2)\n",
    "\n",
    "print(\"\\nBlock 4 abgeschlossen. Ergebnisse:\")\n",
    "print(\" -\", RUN_DIR / \"evaluation.json\")\n",
    "print(\" -\", RUN_DIR / \"figures\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "shap-analysis",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Starte SHAP Analyse ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\jacin\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Berechne SHAP Values für 50 Samples (Background 100)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\jacin\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\backend.py:451: UserWarning: `tf.keras.backend.set_learning_phase` is deprecated and will be removed after 2020-10-11. To update it, simply pass a True/False value to the `training` argument of the `__call__` method of your layer or model.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SHAP Plot gespeichert unter: ..\\results\\2026-01-03_21-02-35_lstm\\figures\\shap_summary.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jacin\\AppData\\Local\\Temp\\ipykernel_40368\\816843332.py:59: FutureWarning: The NumPy global RNG was seeded by calling `np.random.seed`. In a future version this function will no longer use the global RNG. Pass `rng` explicitly to opt-in to the new behaviour and silence this warning.\n",
      "  shap.summary_plot(shap_avg_over_time, X_test_sample_aggr, feature_names=FEATURES, show=False)\n",
      "c:\\Users\\jacin\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\shap\\plots\\_beeswarm.py:723: FutureWarning: The NumPy global RNG was seeded by calling `np.random.seed`. In a future version this function will no longer use the global RNG. Pass `rng` explicitly to opt-in to the new behaviour and silence this warning.\n",
      "  summary_legacy(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# === 19) EXPLAINABLE AI (SHAP) ===\n",
    "# Wir nutzen SHAP (SHapley Additive exPlanations), um zu verstehen, welche Features das Modell treiben.\n",
    "# Da LSTMs auf Sequenzen arbeiten, ist die Interpretation etwas komplexer (Zeit x Feature).\n",
    "\n",
    "print(\"\\n=== Starte SHAP Analyse ===\")\n",
    "import shap\n",
    "# Wir unterdrücken TF2 Warnungen für SHAP, falls nötig\n",
    "# tf.compat.v1.disable_v2_behavior() # Nur aktivieren, falls GradientExplainer Fehler wirft!\n",
    "\n",
    "# 1. Background Data (Zusammenfassung des Trainingssets)\n",
    "# Wir können nicht alle Trainingsdaten nutzen (zu langsam), daher nehmen wir eine zufällige Auswahl.\n",
    "n_background = 100\n",
    "if len(Xtr_win) > n_background:\n",
    "    bg_idx = np.random.choice(len(Xtr_win), n_background, replace=False)\n",
    "    background = Xtr_win[bg_idx]\n",
    "else:\n",
    "    background = Xtr_win\n",
    "\n",
    "# 2. Explainer initialisieren\n",
    "# GradientExplainer ist gut für TF/Keras Modelle geeignet.\n",
    "try:\n",
    "    # Versuche GradientExplainer (erfordert oft Zugriff auf Gradienten im Graph)\n",
    "    explainer = shap.GradientExplainer(model, background)\n",
    "    \n",
    "    # 3. SHAP Values berechnen (für einen Teil des Test-Sets)\n",
    "    # Auch hier limitieren wir auf eine Auswahl, da sehr rechenintensiv.\n",
    "    n_shap_test = 50\n",
    "    if len(Xte_win) > n_shap_test:\n",
    "        test_idx_shap = np.random.choice(len(Xte_win), n_shap_test, replace=False)\n",
    "        X_test_sample = Xte_win[test_idx_shap]\n",
    "    else:\n",
    "        X_test_sample = Xte_win\n",
    "\n",
    "    print(f\"Berechne SHAP Values für {len(X_test_sample)} Samples (Background {len(background)})...\")\n",
    "    shap_values = explainer.shap_values(X_test_sample)\n",
    "\n",
    "    # shap_values ist eine Liste von Arrays (eines pro Output-Klasse). Bei Binärklassifikation oft 1 Array.\n",
    "    if isinstance(shap_values, list):\n",
    "        vals = shap_values[0]\n",
    "    else:\n",
    "        vals = shap_values\n",
    "\n",
    "    # vals shape: (Samples, Lookback, Features)\n",
    "    # Wir wollen Feature Importance pro Feature. \n",
    "    # Möglichkeit A: Summe über die Zeitachse (Feature ist wichtig, egal wann es auftritt)\n",
    "    # Möglichkeit B: Letzter Zeitschritt (Feature ist wichtig, wenn es aktuell ist)\n",
    "    \n",
    "    # Wir nehmen hier die Summe der absoluten SHAP-Werte über die Zeit, oder einfach die Summe.\n",
    "    # Für den normalen Summary Plot braucht SHAP (Samples, Features).\n",
    "    # Wir aggregieren über die Zeitachse (Mittelwert oder Summe).\n",
    "    shap_avg_over_time = np.sum(vals, axis=1) # (Samples, Features)\n",
    "    \n",
    "    # Input Features müssen auch aggregiert werden für die Farbe im Plot (Feature Value high/low)\n",
    "    # Wir nehmen den Mittelwert der Features über die Zeit als Repräsentant\n",
    "    X_test_sample_aggr = np.mean(X_test_sample, axis=1)\n",
    "\n",
    "    # Plot speichern\n",
    "    plt.figure()\n",
    "    shap.summary_plot(shap_avg_over_time, X_test_sample_aggr, feature_names=FEATURES, show=False)\n",
    "    plt.title(\"SHAP Feature Importance (Summed over Time)\")\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(FIG_DIR / \"shap_summary.png\")\n",
    "    plt.close()\n",
    "    print(f\"SHAP Plot gespeichert unter: {FIG_DIR / 'shap_summary.png'}\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"[ERROR] SHAP Analyse fehlgeschlagen: {e}\")\n",
    "    print(\"Mögliche Ursache: TF2 Eager Execution Inkompatibilität. Versuche tf.compat.v1.disable_v2_behavior() am Anfang des Notebooks.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
