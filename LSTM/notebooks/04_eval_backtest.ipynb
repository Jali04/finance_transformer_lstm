{
    "cells": [
        {
            "cell_type": "raw",
            "id": "5df2c55f-8949-47a2-94b9-bb1bc25587a1",
            "metadata": {},
            "source": [
                "# -----------------------------------------\n",
                "# Block 4: Threshold-Tuning, Evaluation, Backtest & Plots\n",
                "# -----------------------------------------\n",
                "# Dieses Notebook ist der \"Richter\". Es bewertet das trainierte Modell.\n",
                "# Schritte:\n",
                "# 1. Val/Test-Splits rekonstruieren (wie im Training)\n",
                "# 2. Kalibrierung prüfen (Sind die Wahrscheinlichkeiten realistisch?)\n",
                "# 3. Besten Schwellenwert (Threshold) auf VALIDATION finden\n",
                "# 4. Finale Performance auf TEST messen (unabhängig!)\n",
                "# 5. Einfacher Backtest (Equity Curve simulieren)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 1,
            "id": "4c69ddd0-9c11-473b-a3c9-56496d3485ab",
            "metadata": {},
            "outputs": [],
            "source": [
                "# === SYSTEM & IMPORTS ===\n",
                "import os, sys, json, time, re, glob\n",
                "from pathlib import Path\n",
                "import numpy as np\n",
                "import pandas as pd\n",
                "import matplotlib.pyplot as plt\n",
                "\n",
                "import tensorflow as tf\n",
                "from tensorflow import keras\n",
                "\n",
                "# Metriken für Klassifikation (AUC, Precision, Recall, etc.)\n",
                "from sklearn.metrics import (\n",
                "    roc_curve, auc, precision_recall_curve, average_precision_score,\n",
                "    classification_report, confusion_matrix, brier_score_loss,\n",
                "    balanced_accuracy_score, matthews_corrcoef\n",
                ")\n",
                "# Kalibrierung und Baseline\n",
                "from sklearn.calibration import calibration_curve, IsotonicRegression\n",
                "from sklearn.linear_model import LogisticRegression\n",
                "import joblib, yaml"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 2,
            "id": "cca0166e-af30-4220-a759-d39d92819921",
            "metadata": {},
            "outputs": [],
            "source": [
                "# === HILFSFUNKTIONEN: LABEL & FILES FINDEN ===\n",
                "# Diese Funktionen helfen uns, automatisch die richtigen Dateien zu finden,\n",
                "# auch wenn wir Parameter geändert haben.\n",
                "\n",
                "def label_from_yaml(featureset: str):\n",
                "    # Liest Horizon, Mode und Epsilon aus der Feature-Config\n",
                "    p = f\"../data/features_{featureset}.yml\"\n",
                "    if os.path.exists(p):\n",
                "        with open(p, \"r\") as f:\n",
                "            meta = yaml.safe_load(f) or {}\n",
                "        lab = (meta.get(\"label\") or {})\n",
                "        H  = lab.get(\"horizon\")\n",
                "        md = lab.get(\"mode\")\n",
                "        eps = lab.get(\"epsilon\")\n",
                "        if H is not None and md is not None and eps is not None:\n",
                "            return int(H), str(md), float(eps)\n",
                "    return None\n",
                "\n",
                "def parse_h_eps_from_path(path: str):\n",
                "    # Extrahiert Parameter aus dem Dateinamen (Regex)\n",
                "    mH = re.search(r\"_cls_h(\\d+)_\", path)\n",
                "    me = re.search(r\"_(abs|rel|q\\d+\\.\\d+)([\\dp.]+)\\.csv$\", path)\n",
                "    H = int(mH.group(1)) if mH else None\n",
                "    if me:\n",
                "        mode, eps_str = me.group(1), me.group(2).replace(\"p\", \".\")\n",
                "        return H, mode, float(eps_str)\n",
                "    return H, None, None\n",
                "\n",
                "def infer_label_from_files(ticker, interval, start, end, H_hint=None, mode_hint=None, eps_hint=None):\n",
                "    # Sucht die neueste passende Trainingsdatei\n",
                "    pat = f\"../data/{ticker}_{interval}_{start}_{end}_cls_h*_.csv\".replace(\"_ .csv\",\".csv\")\n",
                "    cands = sorted(glob.glob(pat), key=os.path.getmtime)\n",
                "    cands = [c for c in cands if (\"_cls_h\" in c)]\n",
                "    if H_hint is not None:\n",
                "        cands = [c for c in cands if f\"_cls_h{H_hint}_\" in c]\n",
                "    if mode_hint and eps_hint is not None:\n",
                "        tag = f\"{mode_hint}{str(eps_hint).replace('.','p')}\"\n",
                "        cands = [c for c in cands if c.endswith(f\"_{tag}.csv\")]\n",
                "    if not cands:\n",
                "        return None\n",
                "    return parse_h_eps_from_path(cands[-1])"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 3,
            "id": "278a7b07-01fd-44f4-8652-467372321368",
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "[Block4] Labels: H=1, mode=abs, epsilon=0.0005\n",
                        "RUN_DIR: ..\\results\\2026-01-01_18-20-06_lstm\n"
                    ]
                }
            ],
            "source": [
                "# === 1) CONFIG & RUN-DIR BESTIMMEN ===\n",
                "ROOT = os.path.abspath(\"..\")\n",
                "if ROOT not in sys.path: sys.path.insert(0, ROOT)\n",
                "\n",
                "# Basis-Config laden\n",
                "with open(os.path.join(ROOT, \"config.json\"), \"r\") as f:\n",
                "    C = json.load(f)\n",
                "\n",
                "TICKER, START, END, INTERVAL = C[\"ticker\"], C[\"start\"], C[\"end\"], C[\"interval\"]\n",
                "LOOKBACK = int(C[\"lookback\"])\n",
                "SEED = int(C.get(\"seed\", 42))\n",
                "FEATURESET = C.get(\"featureset\", \"v2\")\n",
                "\n",
                "# Versuchen, die korrekten Label-Parameter zu bestimmen\n",
                "lbl = label_from_yaml(FEATURESET)\n",
                "if lbl is not None:\n",
                "    HORIZON, EPS_MODE, EPSILON = lbl\n",
                "else:\n",
                "    # Fallback: Aus Dateinamen raten\n",
                "    HORIZON, EPS_MODE, EPSILON = infer_label_from_files(TICKER, INTERVAL, START, END)\n",
                "    if HORIZON is None or EPS_MODE is None or EPSILON is None:\n",
                "        raise RuntimeError(\"Label-Definition (H/mode/epsilon) konnte nicht bestimmt werden. Block 2 nötig.\")\n",
                "\n",
                "print(f\"[Block4] Labels: H={HORIZON}, mode={EPS_MODE}, epsilon={EPSILON}\")\n",
                "np.random.seed(SEED); tf.random.set_seed(SEED)\n",
                "RESULTS_DIR = Path(C.get(\"results_dir\", \"../results\"))\n",
                "\n",
                "# Den passenden (neuesten) Run-Ordner finden\n",
                "def _latest_run_dir_matching(results_dir: Path, H: int, eps_mode: str, eps: float) -> Path:\n",
                "    tag = f\"{eps_mode}{str(eps).replace('.','p')}\"\n",
                "    runs = sorted(results_dir.glob(\"*_lstm\"), key=lambda p: p.stat().st_mtime, reverse=True)\n",
                "    for r in runs:\n",
                "        cfgp = r / \"config.json\"\n",
                "        if not cfgp.exists(): continue\n",
                "        try:\n",
                "            with open(cfgp, \"r\") as f:\n",
                "                rcfg = json.load(f)\n",
                "            # Prüfen ob Parameter übereinstimmen\n",
                "            ok_lb = int(rcfg.get(\"lookback\", LOOKBACK)) == LOOKBACK\n",
                "            ok_h  = (int(rcfg.get(\"horizon\", H)) == H) or ((\"_cls_h\"+str(H)+\"_\") in str(rcfg.get(\"train_csv\",\"\")))\n",
                "            ok_eps= (tag in str(rcfg.get(\"train_csv\",\"\")))\n",
                "            if ok_lb and ok_h and ok_eps:\n",
                "                return r\n",
                "        except Exception:\n",
                "            pass\n",
                "    # Fallback: Einfach den allerneuesten nehmen\n",
                "    if runs:\n",
                "        return runs[0]\n",
                "    raise FileNotFoundError(\"Kein RUN_DIR gefunden – bitte Block 3 trainieren.\")\n",
                "\n",
                "RUN_DIR = _latest_run_dir_matching(RESULTS_DIR, HORIZON, EPS_MODE, EPSILON)\n",
                "print(\"RUN_DIR:\", RUN_DIR)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 4,
            "id": "70085932-0e7c-4267-a84a-55b823b98d9b",
            "metadata": {},
            "outputs": [],
            "source": [
                "# === 2) ARTEFAKTE LADEN (Model, Scaler, Config) ===\n",
                "ENV_INFO = RUN_DIR / \"env_info.json\"\n",
                "MODEL_PATH = RUN_DIR / \"model.keras\"\n",
                "BEST_PATH  = RUN_DIR / \"best.keras\"\n",
                "SCALER_PATH = RUN_DIR / \"scaler.joblib\"\n",
                "CFG_PATH    = RUN_DIR / \"config.json\"\n",
                "\n",
                "# Falls vorhanden, lieber das 'best.keras' (vom Checkpoint) nehmen\n",
                "if BEST_PATH.exists():\n",
                "    MODEL_PATH = BEST_PATH\n",
                "\n",
                "# Dateien prüfen\n",
                "assert MODEL_PATH.exists(), f\"Model-File fehlt: {MODEL_PATH}\"\n",
                "assert SCALER_PATH.exists(), f\"Scaler-File fehlt: {SCALER_PATH}\"\n",
                "assert CFG_PATH.exists(),    f\"Run-Config fehlt: {CFG_PATH}\"\n",
                "\n",
                "with open(CFG_PATH, \"r\") as f:\n",
                "    RCFG = json.load(f)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 5,
            "id": "e61e4baf-7d92-4cc9-b8c3-23210146cd05",
            "metadata": {},
            "outputs": [],
            "source": [
                "# === 3) KONSISTENZPRÜFUNG & MODELL-LOAD ===\n",
                "# Prüfen, ob das geladene Modell zu unseren Parametern passt\n",
                "def _parse_h_mode_eps_from_train_csv(path: str):\n",
                "    mH = re.search(r\"_cls_h(\\d+)_\", path)\n",
                "    me = re.search(r\"_(abs|rel|q\\d+\\.\\d+)([\\dp.]+)\\.csv$\", path)\n",
                "    H = int(mH.group(1)) if mH else None\n",
                "    mode = me.group(1) if me else None\n",
                "    eps = float(me.group(2).replace(\"p\",\".\")) if me else None\n",
                "    return H, mode, eps\n",
                "\n",
                "run_h_cfg = int(RCFG.get(\"horizon\", HORIZON))\n",
                "run_lb    = int(RCFG.get(\"lookback\", LOOKBACK))\n",
                "train_csv_in_cfg = str(RCFG.get(\"train_csv\", \"\"))\n",
                "\n",
                "h_from_name, mode_from_name, eps_from_name = _parse_h_mode_eps_from_train_csv(train_csv_in_cfg)\n",
                "\n",
                "assert run_lb == LOOKBACK, f\"Inkompatibler Lookback: run={run_lb} vs. core={LOOKBACK}\"\n",
                "\n",
                "# Warnung, falls Diskrepanzen (aber kein Abbruch)\n",
                "ok_h  = (run_h_cfg == HORIZON) or (h_from_name == HORIZON)\n",
                "ok_m  = (mode_from_name is None) or (mode_from_name == EPS_MODE)\n",
                "ok_e  = (eps_from_name  is None) or (np.isclose(eps_from_name, EPSILON))\n",
                "\n",
                "if not (ok_h and ok_m and ok_e):\n",
                "    print(\"[WARN] Run-Config uneindeutig zu Label-Definition:\",\n",
                "          f\"RCFG.horizon={run_h_cfg}, parsed_from_name={h_from_name}, target={HORIZON},\",\n",
                "          f\"mode_in_name={mode_from_name}, target_mode={EPS_MODE},\",\n",
                "          f\"eps_in_name={eps_from_name}, target_eps={EPSILON} — fahre mit H/M/E aus Daten fort.\")\n",
                "\n",
                "# Modell und Scaler laden\n",
                "model  = keras.models.load_model(MODEL_PATH, compile=False)\n",
                "scaler = joblib.load(SCALER_PATH)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 6,
            "id": "823511f8-37a8-45ef-b581-8afa6625874a",
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "TRAIN_CSV: ../data/AAPL_1d_2010-01-01_2026-01-01_cls_h1_abs0p0005.csv\n"
                    ]
                }
            ],
            "source": [
                "# === 4) ORIGINAL-DATEN LADEN ===\n",
                "# Wir müssen die Daten exakt so laden wie im Training, um Features und Splits zu rekonstruieren\n",
                "eps_tag = f\"{EPS_MODE}{str(EPSILON).replace('.','p')}\"\n",
                "train_exact = f\"../data/{TICKER}_{INTERVAL}_{START}_{END}_cls_h{HORIZON}_{eps_tag}.csv\"\n",
                "if not os.path.exists(train_exact):\n",
                "    # Fallback Suche nach Datei\n",
                "    pat = f\"../data/{TICKER}_{INTERVAL}_{START}_{END}_cls_h{HORIZON}_{eps_tag}.csv\"\n",
                "    cands = sorted(glob.glob(pat), key=os.path.getmtime)\n",
                "    if not cands:\n",
                "        raise FileNotFoundError(\n",
                "            f\"Train CSV nicht gefunden (H={HORIZON}, tag={eps_tag}): {train_exact}\\n\"\n",
                "            \"Bitte Block 2 mit dieser Label-Definition laufen lassen.\"\n",
                "        )\n",
                "    TRAIN_CSV = cands[-1]\n",
                "else:\n",
                "    TRAIN_CSV = train_exact\n",
                "\n",
                "print(\"TRAIN_CSV:\", TRAIN_CSV)\n",
                "df = pd.read_csv(TRAIN_CSV, index_col=0, parse_dates=True).sort_index()\n",
                "\n",
                "with open(RUN_DIR / \"config.json\", \"r\") as f:\n",
                "    RCFG = json.load(f)\n",
                "if int(RCFG.get(\"lookback\", LOOKBACK)) != LOOKBACK:\n",
                "    raise AssertionError(f\"Inkompatibler Lookback: run={RCFG.get('lookback')} vs. core={LOOKBACK}\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 7,
            "id": "c5efa39e-b149-4c17-ba76-cf9cbb384b37",
            "metadata": {},
            "outputs": [],
            "source": [
                "# === 5) FEATURE-SET BESTIMMEN ===\n",
                "# Welche Features wurden trainiert? Das steht in der Config.\n",
                "if \"features\" in RCFG and RCFG[\"features\"]:\n",
                "    FEATURES = [c for c in RCFG[\"features\"] if c in df.columns]\n",
                "else:\n",
                "    with open(f\"../data/features_{FEATURESET}.yml\",\"r\") as f:\n",
                "        meta = yaml.safe_load(f) or {}\n",
                "    FEATURES = [c for c in meta.get(\"features\", []) if c in df.columns]\n",
                "assert len(FEATURES) > 0, \"Keine Features gefunden.\"\n",
                "\n",
                "X = df[FEATURES].copy()\n",
                "y = df[\"target\"].astype(int).copy()"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 8,
            "id": "24824a33-b6a3-4b61-b363-2551d40fda8c",
            "metadata": {},
            "outputs": [],
            "source": [
                "# === 6) SPLIT WIEDERHERSTELLEN ===\n",
                "# Exakt dieselben Splits wie im Training, damit Val und Test sauber bleiben\n",
                "n = len(df)\n",
                "n_train = int(n*0.70); n_val = int(n*0.15); n_test = n - n_train - n_val\n",
                "train_idx = slice(0, n_train)\n",
                "val_idx   = slice(n_train, n_train + n_val)\n",
                "test_idx  = slice(n_train + n_val, n)\n",
                "\n",
                "X_train, y_train = X.iloc[train_idx], y.iloc[train_idx]\n",
                "X_val,   y_val   = X.iloc[val_idx],   y.iloc[val_idx]\n",
                "X_test,  y_test  = X.iloc[test_idx],  y.iloc[test_idx]"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 9,
            "id": "6584d486-4b95-4f2c-a270-0fd2c5fc839a",
            "metadata": {},
            "outputs": [],
            "source": [
                "# === 7) SKALIERUNG ANWENDEN ===\n",
                "# Den geladenen Scaler nutzen (nicht neu fitten!)\n",
                "X_train_s = pd.DataFrame(scaler.transform(X_train), index=X_train.index, columns=FEATURES)\n",
                "X_val_s   = pd.DataFrame(scaler.transform(X_val),   index=X_val.index,   columns=FEATURES)\n",
                "X_test_s  = pd.DataFrame(scaler.transform(X_test),  index=X_test.index,  columns=FEATURES)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 10,
            "id": "9aebd466-487b-4b3f-b3c5-f3dad3a88c6c",
            "metadata": {},
            "outputs": [],
            "source": [
                "# === 8) WINDOWING (Datenaufbereitung für LSTM) ===\n",
                "def make_windows(X_df, y_ser, lookback):\n",
                "    Xv = X_df.values.astype(np.float32); yv = y_ser.values.astype(np.int32)\n",
                "    xs, ys, idx_end = [], [], []\n",
                "    for i in range(lookback-1, len(X_df)):\n",
                "        xs.append(Xv[i - lookback + 1 : i + 1]); ys.append(yv[i]); idx_end.append(X_df.index[i])\n",
                "    return np.stack(xs, 0), np.array(ys), pd.DatetimeIndex(idx_end)\n",
                "\n",
                "Xtr_win, ytr, idx_tr = make_windows(X_train_s, y_train, LOOKBACK)\n",
                "Xva_win, yva, idx_va = make_windows(X_val_s,   y_val,   LOOKBACK)\n",
                "Xte_win, yte, idx_te = make_windows(X_test_s,  y_test,  LOOKBACK)\n",
                "\n",
                "def to_ds(X, y, batch, shuffle):\n",
                "    ds = tf.data.Dataset.from_tensor_slices((X, y))\n",
                "    if shuffle: ds = ds.shuffle(len(X), seed=SEED, reshuffle_each_iteration=False)\n",
                "    return ds.batch(int(C.get(\"batch\", 64))).prefetch(tf.data.AUTOTUNE)\n",
                "\n",
                "ds_val  = to_ds(Xva_win, yva, int(C.get(\"batch\",64)), shuffle=False)\n",
                "ds_test = to_ds(Xte_win, yte, int(C.get(\"batch\",64)), shuffle=False)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 11,
            "id": "c71bb7ef-7955-4b2f-b901-68f04327ec44",
            "metadata": {},
            "outputs": [],
            "source": [
                "# === 9) VORHERSAGEN (PREDICTION) ===\n",
                "# Wir generieren Rohe Wahrscheinlichkeiten (0...1) für Validation und Test\n",
                "y_val_proba  = model.predict(ds_val,  verbose=0).ravel()\n",
                "y_test_proba = model.predict(ds_test, verbose=0).ravel()"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 12,
            "id": "8f1ac0c3-a5b9-4799-bff4-7eff4450611f",
            "metadata": {},
            "outputs": [],
            "source": [
                "# === 10) KALIBRIERUNG PRÜFEN ===\n",
                "# Manchmal sind Keras-Wahrscheinlichkeiten nicht \"echt\" (z.B. alles zwischen 0.4 und 0.6).\n",
                "# Methoden wie Isotonic Regression oder Platt Scaling können das korrigieren.\n",
                "\n",
                "# Isotonic Regression (nicht-parametrisch)\n",
                "iso = IsotonicRegression(out_of_bounds=\"clip\").fit(y_val_proba, yva)\n",
                "val_iso  = iso.transform(y_val_proba)\n",
                "test_iso = iso.transform(y_test_proba)\n",
                "\n",
                "# Platt Scaling (Logistische Regression auf den Outputs)\n",
                "platt = LogisticRegression(max_iter=1000)\n",
                "platt.fit(y_val_proba.reshape(-1,1), yva)\n",
                "val_platt  = platt.predict_proba(y_val_proba.reshape(-1,1))[:,1]\n",
                "test_platt = platt.predict_proba(y_test_proba.reshape(-1,1))[:,1]\n",
                "\n",
                "# Brier Score misst die Qualität der Wahrscheinlichkeit (wie MSE, je kleiner desto besser)\n",
                "brier_val_raw   = brier_score_loss(yva, y_val_proba)\n",
                "brier_val_iso   = brier_score_loss(yva, val_iso)\n",
                "brier_val_platt = brier_score_loss(yva, val_platt)\n",
                "\n",
                "# Wer ist besser auf Validation? Iso oder Platt?\n",
                "if brier_val_platt <= brier_val_iso:\n",
                "    cand_name, val_cand, test_cand, cand_obj = \"platt\", val_platt, test_platt, platt\n",
                "    brier_val_cand = brier_val_platt\n",
                "else:\n",
                "    cand_name, val_cand, test_cand, cand_obj = \"isotonic\", val_iso, test_iso, iso\n",
                "    brier_val_cand = brier_val_iso"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 13,
            "id": "c12c8596-1e24-4d3d-b294-2578e6f34274",
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "[Kalibrierung] chosen=isotonic | ΔBrier(VAL)=76.2 bp | Test Brier raw→cand 0.2547→0.2503 (nur Bericht)\n"
                    ]
                }
            ],
            "source": [
                "# === 11) KALIBRIERUNG ENTSCHEIDEN ===\n",
                "# Wir akzeptieren die Kalibrierung nur, wenn sie den Brier Score signifikant verbessert (> 1 Basispunkt).\n",
                "# WICHTIG: Entscheidung NUR auf Basis der Validation Daten!\n",
                "min_gain_bp = 1.0  # 1 bp = 0.0001\n",
                "gain_bp = (brier_val_raw - brier_val_cand) * 1e4\n",
                "\n",
                "brier_test_raw  = brier_score_loss(yte, y_test_proba)   # nur zur Info\n",
                "brier_test_cand = brier_score_loss(yte, test_cand)      # nur zur Info\n",
                "\n",
                "use_cal = (brier_val_raw - brier_val_cand) > 1e-4\n",
                "if use_cal:\n",
                "    CAL_METHOD, y_val_cal, y_test_cal = cand_name, val_cand, test_cand\n",
                "    joblib.dump(cand_obj, RUN_DIR / f\"calibrator_{CAL_METHOD}.joblib\")\n",
                "else:\n",
                "    CAL_METHOD, y_val_cal, y_test_cal = \"none\", y_val_proba, y_test_proba\n",
                "\n",
                "print(f\"[Kalibrierung] chosen={CAL_METHOD} | ΔBrier(VAL)={gain_bp:.1f} bp \"\n",
                "      f\"| Test Brier raw→cand {brier_test_raw:.4f}→{brier_test_cand:.4f} (nur Bericht)\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 14,
            "id": "044f863e-5335-4c87-b4ed-079c27b30794",
            "metadata": {},
            "outputs": [],
            "source": [
                "# === 12) OPTIMALEN THRESHOLD FINDEN ===\n",
                "# Standard Threshold ist 0.5. Das ist aber oft nicht ideal.\n",
                "# Wir suchen den Wert, der den MCC (Matthews Correlation Coefficient) auf VALIDATION maximiert.\n",
                "# Bounds: Wir suchen nur in der Nähe der 'echten' Positivrate (Klassengleichgewicht).\n",
                "\n",
                "def choose_threshold(y_true, y_prob, pos_rate_bounds=(0.45,0.55)):\n",
                "    uniq = np.unique(y_prob); cand = np.r_[0.0, uniq, 1.0]\n",
                "    best_t, best_s = 0.5, -1.0\n",
                "    for t in cand:\n",
                "        yp = (y_prob >= t).astype(int)\n",
                "        pr = float(yp.mean())\n",
                "        if not (pos_rate_bounds[0] <= pr <= pos_rate_bounds[1]):\n",
                "            continue\n",
                "        s = matthews_corrcoef(y_true, yp)\n",
                "        if s > best_s: best_s, best_t = float(s), float(t)\n",
                "    if best_s < 0:\n",
                "        return 0.5, 0.0\n",
                "    return best_t, best_s\n",
                "\n",
                "p_val = float(yva.mean())\n",
                "bounds = (max(0.0, p_val - 0.10), min(1.0, p_val + 0.10))\n",
                "thr, score_val = choose_threshold(yva, y_val_cal, pos_rate_bounds=bounds)\n",
                "\n",
                "# Statistische Spielerei (unbounded search als Referenz)\n",
                "def best_mcc_unbounded(y_true, y_prob):\n",
                "    # ... (code omitted for brevity in comments)\n",
                "    ts = np.r_[0.0, np.unique(y_prob), 1.0]\n",
                "    best = (-1.0, 0.5)\n",
                "    for t in ts:\n",
                "        m = matthews_corrcoef(y_true, (y_prob >= t).astype(int))\n",
                "        if m > best[0]: best = (float(m), float(t))\n",
                "    return best\n",
                "\n",
                "def best_youden_j(y_true, y_prob):\n",
                "    # ... (Youden's J statistic)\n",
                "    ts = np.r_[0.0, np.unique(y_prob), 1.0]\n",
                "    best = (-1.0, 0.5)\n",
                "    from sklearn.metrics import confusion_matrix\n",
                "    for t in ts:\n",
                "        yhat = (y_prob >= t).astype(int)\n",
                "        cm = confusion_matrix(y_true, yhat)\n",
                "        tn, fp, fn, tp = cm.ravel()\n",
                "        sens = tp / (tp + fn + 1e-12)\n",
                "        spec = tn / (tn + fp + 1e-12)\n",
                "        J = sens + spec - 1.0\n",
                "        if J > best[0]: best = (float(J), float(t))\n",
                "    return best\n",
                "\n",
                "mcc_raw, thr_mcc_raw = best_mcc_unbounded(yva, y_val_cal)\n",
                "J_raw,   thr_J_raw   = best_youden_j(yva, y_val_cal)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 15,
            "id": "df77d65d-26fe-4609-898c-800dee5c857d",
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Confusion matrix (test):\n",
                        " [[ 65 191]\n",
                        " [ 67 218]]\n",
                        "MCC=0.022 | BalAcc=0.509 | AUROC=0.508 | AUPRC=0.532 (baseline=0.527) | Brier raw→used 0.2547→0.2503 | thr=0.500 | pred_pos_rate(test)=0.756\n"
                    ]
                }
            ],
            "source": [
                "# === 13) FINALE TEST-EVALUATION (@ chosen Threshold) ===\n",
                "y_test_pred = (y_test_cal >= thr).astype(int)\n",
                "\n",
                "cm   = confusion_matrix(yte, y_test_pred)\n",
                "rep  = classification_report(yte, y_test_pred, digits=3, output_dict=True)\n",
                "fpr, tpr, _ = roc_curve(yte, y_test_cal); roc_auc = auc(fpr, tpr)\n",
                "prec, rec, _ = precision_recall_curve(yte, y_test_cal); ap = average_precision_score(yte, y_test_cal)\n",
                "\n",
                "# Random Baseline für PR-AUC = Anteil der positiven Labels\n",
                "ap_baseline_val  = float(yva.mean())\n",
                "ap_baseline_test = float(yte.mean())\n",
                "\n",
                "brier_raw = brier_score_loss(yte, y_test_proba)\n",
                "brier_cal = brier_score_loss(yte, y_test_cal)\n",
                "bal_acc = balanced_accuracy_score(yte, y_test_pred)\n",
                "mcc     = matthews_corrcoef(yte, y_test_pred)\n",
                "pos_rate_test = float(y_test_pred.mean())\n",
                "\n",
                "print(\"Confusion matrix (test):\\n\", cm)\n",
                "print(f\"MCC={mcc:.3f} | BalAcc={bal_acc:.3f} | AUROC={roc_auc:.3f} | \"\n",
                "      f\"AUPRC={ap:.3f} (baseline={ap_baseline_test:.3f}) | \"\n",
                "      f\"Brier raw→used {brier_raw:.4f}→{brier_cal:.4f} | thr={thr:.3f} | pred_pos_rate(test)={pos_rate_test:.3f}\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 16,
            "id": "e1404cda-f83e-43b6-8e8b-e31d868a1ae7",
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "MCC Bootstrap CI [2.5,50,97.5]: [np.float64(-0.045), np.float64(0.032), np.float64(0.107)]\n"
                    ]
                }
            ],
            "source": [
                "# === 14) BOOTSTRAP KONFIDENZINTREVALL (MCC) ===\n",
                "# Ist unser Ergebnis statistisch signifikant?\n",
                "rng = np.random.default_rng(SEED)\n",
                "def block_bootstrap_mcc(y_true, y_prob, threshold, n=300, block=LOOKBACK):\n",
                "    idx = np.arange(len(y_true))\n",
                "    scores = []\n",
                "    for _ in range(n):\n",
                "        # Blocksampling (Zeitstruktur erhalten)\n",
                "        starts = rng.integers(0, max(1, len(idx)-block+1), size=max(1, len(idx)//block))\n",
                "        bs = np.concatenate([np.arange(s, min(s+block, len(idx))) for s in starts])\n",
                "        yp = (y_prob[bs] >= threshold).astype(int)\n",
                "        scores.append(matthews_corrcoef(y_true[bs], yp))\n",
                "    return np.percentile(scores, [2.5, 50, 97.5]).astype(float)\n",
                "\n",
                "mcc_ci = block_bootstrap_mcc(yte, y_test_cal, thr, n=300, block=LOOKBACK)\n",
                "print(\"MCC Bootstrap CI [2.5,50,97.5]:\", [round(x,3) for x in mcc_ci])"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 17,
            "id": "262a19eb-6fcf-415c-80ae-3eb318ce44dc",
            "metadata": {},
            "outputs": [],
            "source": [
                "# === 15) DIAGNOSE-PLOTS SPEICHERN ===\n",
                "FIG_DIR = RUN_DIR / \"figures\"; FIG_DIR.mkdir(exist_ok=True, parents=True)\n",
                "\n",
                "# ROC Curve\n",
                "plt.figure(figsize=(6,4)); plt.plot(fpr, tpr, label=f\"AUC={roc_auc:.3f}\")\n",
                "plt.plot([0,1],[0,1],\"--\"); plt.xlabel(\"FPR\"); plt.ylabel(\"TPR\"); plt.title(\"ROC (Test)\")\n",
                "plt.legend(); plt.tight_layout(); plt.savefig(FIG_DIR / \"roc_test.png\", dpi=160); plt.close()\n",
                "\n",
                "# Precision-Recall Curve (mit Random-Baseline)\n",
                "plt.figure(figsize=(6,4))\n",
                "plt.plot(rec, prec, label=f\"AP={ap:.3f} (base={ap_baseline_test:.3f})\")\n",
                "plt.hlines(ap_baseline_test, xmin=0, xmax=1, linestyles=\"--\", label=\"Random baseline\")\n",
                "plt.xlabel(\"Recall\"); plt.ylabel(\"Precision\"); plt.title(\"Precision-Recall (Test)\")\n",
                "plt.legend(); plt.tight_layout(); plt.savefig(FIG_DIR / \"pr_test.png\", dpi=160); plt.close()\n",
                "\n",
                "# Kalibrierungskurve\n",
                "prob_true, prob_pred = calibration_curve(yte, y_test_cal, n_bins=10, strategy=\"quantile\")\n",
                "plt.figure(figsize=(6,4)); plt.plot([0,1],[0,1],\"--\"); plt.plot(prob_pred, prob_true, marker=\"o\")\n",
                "plt.xlabel(\"Vorhergesagt\"); plt.ylabel(\"Tatsächlich\"); plt.title(f\"Kalibrierung (Test) – {CAL_METHOD}\")\n",
                "plt.tight_layout(); plt.savefig(FIG_DIR / \"calibration_test.png\", dpi=160); plt.close()\n",
                "\n",
                "# Confusion Matrix Visualisierung\n",
                "plt.figure(figsize=(4.8,4.2))\n",
                "plt.imshow(cm, interpolation=\"nearest\"); plt.title(\"Confusion Matrix (Test)\"); plt.colorbar()\n",
                "ticks = np.arange(2); plt.xticks(ticks, [\"0\",\"1\"]); plt.yticks(ticks, [\"0\",\"1\"])\n",
                "for i in range(cm.shape[0]):\n",
                "    for j in range(cm.shape[1]):\n",
                "        plt.text(j, i, cm[i, j], ha=\"center\", va=\"center\")\n",
                "plt.xlabel(\"Predicted\"); plt.ylabel(\"True\")\n",
                "plt.tight_layout(); plt.savefig(FIG_DIR / \"cm_test.png\", dpi=160); plt.close()\n",
                "\n",
                "# Wahrscheinlichkeits-Histogramm\n",
                "plt.figure(figsize=(6,4))\n",
                "plt.hist(y_test_proba, bins=30, alpha=0.6, label=\"raw\")\n",
                "plt.hist(y_test_cal,   bins=30, alpha=0.6, label=f\"used ({CAL_METHOD})\")\n",
                "plt.axvline(thr, linestyle=\"--\", label=f\"thr={thr:.3f}\")\n",
                "plt.title(\"P(y=1) – raw vs. used (Test)\")\n",
                "plt.legend(); plt.tight_layout()\n",
                "plt.savefig(FIG_DIR / \"proba_hist_raw_vs_used.png\", dpi=160); plt.close()"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 18,
            "id": "08cfd2af-70a6-4187-ab6f-c0ffb4d3c9a7",
            "metadata": {},
            "outputs": [],
            "source": [
                "# === 16) VORHERSAGEN SPEICHERN ===\n",
                "preds_test = pd.DataFrame({\n",
                "    \"timestamp\": idx_te, \"y_true\": yte,\n",
                "    \"y_proba_raw\": y_test_proba, \"y_proba_used\": y_test_cal, \"y_pred\": y_test_pred,\n",
                "}).set_index(\"timestamp\")\n",
                "preds_test.to_csv(RUN_DIR / \"preds_test.csv\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 19,
            "id": "ac31e9e3-bb48-4f08-b07b-01adcb99f752",
            "metadata": {},
            "outputs": [],
            "source": [
                "# === 17) EINFACHER BACKTEST (Equity Curves) ===\n",
                "# T+1 Entry Simulation (realistisch) und T Entry (optimistisch/unmöglich)\n",
                "close = df[\"close\"].copy()\n",
                "fwd_logret = (np.log(close.shift(-HORIZON)) - np.log(close)).reindex(idx_te)\n",
                "\n",
                "# Signale\n",
                "signals_t  = (preds_test[\"y_proba_used\"] >= thr).astype(int).reindex(idx_te)\n",
                "signals_t1 = signals_t.shift(1).fillna(0) # Wir kaufen am Tag NACH dem Signal\n",
                "\n",
                "# Renditen der Strategie\n",
                "strategy_logret_t  = (signals_t  * fwd_logret).fillna(0)\n",
                "strategy_logret_t1 = (signals_t1 * fwd_logret).fillna(0)\n",
                "equity_t  = strategy_logret_t.cumsum().apply(np.exp) # Wertentwicklung\n",
                "equity_t1 = strategy_logret_t1.cumsum().apply(np.exp)\n",
                "\n",
                "# Buy & Hold Vergleich\n",
                "bh_logret = (np.log(close.reindex(idx_te)) - np.log(close.reindex(idx_te).iloc[0])).fillna(0)\n",
                "bh_equity = np.exp(bh_logret)\n",
                "\n",
                "# KPIs (Sharpe, CAGR)\n",
                "def _sharpe(logrets, periods_per_year=252):\n",
                "    mu = logrets.mean() * periods_per_year\n",
                "    sigma = logrets.std(ddof=1) * np.sqrt(periods_per_year)\n",
                "    return float(mu / (sigma + 1e-12))\n",
                "\n",
                "def _cagr(eq, periods_per_year=252):\n",
                "    T = len(eq) / periods_per_year\n",
                "    return float((eq.iloc[-1] / eq.iloc[0])**(1.0/max(T,1e-12)) - 1.0)\n",
                "\n",
                "backtest = {\n",
                "    \"n_trades\": int(signals_t.sum()),\n",
                "    \"avg_holding_h\": HORIZON,\n",
                "    \"strategy_t\":  {\"CAGR\": _cagr(equity_t),  \"Sharpe\": _sharpe(strategy_logret_t.dropna()),  \"final_equity\": float(equity_t.iloc[-1])},\n",
                "    \"strategy_t1\": {\"CAGR\": _cagr(equity_t1), \"Sharpe\": _sharpe(strategy_logret_t1.dropna()), \"final_equity\": float(equity_t1.iloc[-1])},\n",
                "    \"buy_hold\":    {\"CAGR\": _cagr(bh_equity), \"final_equity\": float(bh_equity.iloc[-1])},\n",
                "}\n",
                "\n",
                "# Equity Curve Plot\n",
                "plt.figure(figsize=(8,4))\n",
                "plt.plot(equity_t.index, equity_t.values,   label=\"Entry@t (optimistisch / Referenz)\")\n",
                "plt.plot(equity_t1.index, equity_t1.values, label=\"Entry@t+1 (realistische KPI-Basis)\")\n",
                "plt.plot(bh_equity.index, bh_equity.values, label=\"Buy & Hold\", linestyle=\"--\")\n",
                "plt.title(f\"Equity Curves (H={HORIZON})\")\n",
                "plt.legend(); plt.tight_layout(); plt.savefig(FIG_DIR / \"equity_curves_t_vs_t1.png\", dpi=160); plt.close()"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 20,
            "id": "200036f8-d7ff-41fe-aa6f-ae6903888710",
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "\n",
                        "Block 4 abgeschlossen. Artefakte:\n",
                        " - ..\\results\\2026-01-01_18-20-06_lstm\\preds_test.csv\n",
                        " - ..\\results\\2026-01-01_18-20-06_lstm\\evaluation.json\n",
                        " - ..\\results\\2026-01-01_18-20-06_lstm\\figures\n"
                    ]
                }
            ],
            "source": [
                "# === 18) ALLES ZUSAMMENFASSEN & SPEICHERN ===\n",
                "out = {\n",
                "    \"config\": RCFG,\n",
                "    \"features_used\": FEATURES,\n",
                "    \"calibration\": {\n",
                "        \"chosen\": CAL_METHOD,\n",
                "        \"paths\": ({} if CAL_METHOD==\"none\" else {CAL_METHOD: str(RUN_DIR / f\"calibrator_{CAL_METHOD}.joblib\")}),\n",
                "        \"val_brier\": {\"raw\": float(brier_val_raw), \"iso\": float(brier_val_iso), \"platt\": float(brier_val_platt)},\n",
                "        \"test_brier\": {\"raw\": float(brier_test_raw), \"candidate\": float(brier_test_cand), \"used\": float(brier_cal)}\n",
                "    },\n",
                "    \"label_resolved_from\": {\n",
                "        \"features_yaml\": f\"../data/features_{FEATURESET}.yml\",\n",
                "        \"ticker\": TICKER, \"interval\": INTERVAL, \"start\": START, \"end\": END,\n",
                "        \"horizon\": HORIZON, \"mode\": EPS_MODE, \"epsilon\": EPSILON\n",
                "    },\n",
                "    \"threshold_selection\": {\n",
                "        \"strategy\": \"max_mcc_with_pos_rate_bounds_centered_on_val_rate\",\n",
                "        \"threshold\": float(thr),\n",
                "        \"pos_rate_bounds\": [float(bounds[0]), float(bounds[1])],\n",
                "        \"val_pos_rate\": p_val,\n",
                "        \"val_mcc\": float(score_val),\n",
                "        \"val_mcc_unbounded\": {\"mcc\": float(mcc_raw), \"thr\": float(thr_mcc_raw)},\n",
                "        \"val_youden_j\": {\"J\": float(J_raw), \"thr\": float(thr_J_raw)},\n",
                "        \"test_pred_pos_rate\": pos_rate_test\n",
                "    },\n",
                "    \"metrics\": {\n",
                "        \"test\": {\n",
                "            \"roc_auc\": float(roc_auc),\n",
                "            \"auprc\": float(ap),\n",
                "            \"auprc_baseline\": ap_baseline_test,\n",
                "            \"brier\": float(brier_cal),\n",
                "            \"balanced_accuracy\": float(bal_acc),\n",
                "            \"mcc\": float(mcc),\n",
                "            \"confusion_matrix\": cm.tolist(),\n",
                "            \"report\": rep\n",
                "        },\n",
                "        \"mcc_bootstrap_ci\": [float(x) for x in mcc_ci.tolist()]\n",
                "    },\n",
                "    \"backtest\": backtest,\n",
                "    \"report_notes\": {\n",
                "        \"kpi_basis\": \"entry_t1\",\n",
                "        \"entry_t_is_upper_bound\": True,\n",
                "        \"pr_auc_baseline_note\": \"random baseline equals positive rate\"\n",
                "    }\n",
                "}\n",
                "with open(RUN_DIR / \"evaluation.json\", \"w\") as f:\n",
                "    json.dump(out, f, indent=2)\n",
                "\n",
                "print(\"\\nBlock 4 abgeschlossen. Artefakte:\")\n",
                "print(\" -\", RUN_DIR / \"preds_test.csv\")\n",
                "print(\" -\", RUN_DIR / \"evaluation.json\")\n",
                "print(\" -\", RUN_DIR / \"figures\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "34c23181-39d6-4d12-b294-a152d62e251b",
            "metadata": {},
            "outputs": [],
            "source": []
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.10.11"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 5
}
